

# **课程总览与学习路径**



这个课程体系旨在带领学员从零开始，逐步掌握从开发、部署到运维一个完整的微服务系统所需的核心技能。我们将以一个贯穿始终的实战项目（例如，一个简化的电商系统）为驱动，在每门课程中不断演进和完善它。

学习路径:

容器化基础 -> 单体应用开发 -> 微服务改造与治理 -> 生产级部署与编排 -> 全方位监控与运维 -> CSE微服务改造

------



### **第一门课：云原生基石 —— Docker 容器化技术详解**



**课程目标：** 使学员完全掌握 Docker 的核心概念和实践操作，能够将任何应用程序容器化，并使用 Docker Compose 进行多服务环境的搭建，为微服务和 K8s 打下坚实基础。

**章节设计:**

- **第1章：课程介绍与环境准备**
  - 1.1 微服务时代为什么要学 Docker？
  - 1.2 课程项目介绍与技术栈概览
  - 1.3 Docker 在各平台 (Windows/macOS/Linux) 的安装与配置
  - 1.4 配置 Docker Hub 镜像加速器
- **第2章：Docker 核心概念与命令**
  - 2.1 镜像 (Image) vs 容器 (Container) vs 仓库 (Registry)
  - 2.2 Docker 引擎架构详解
  - 2.3 镜像核心命令: `pull`, `images`, `search`, `rmi`, `push`
  - 2.4 容器生命周期: `run`, `ps`, `start`, `stop`, `restart`, `rm`, `logs`
  - 2.5 交互式容器: `exec`, `attach`
- **第3章：Dockerfile - 构建自己的镜像**
  - 3.1 Dockerfile 核心指令详解 (FROM, RUN, COPY, ADD, CMD, ENTRYPOINT, ENV)
  - 3.2 **实战项目一：** 将一个 Spring Boot 单体应用打包成 Docker 镜像
  - 3.3 Dockerfile 最佳实践与镜像层 (Layer) 概念
  - 3.4 多阶段构建 (Multi-stage Build) - 极致优化镜像体积
- **第4章：Docker 网络与数据管理**
  - 4.1 Docker 的网络模式：`bridge`, `host`, `none`, `container`
  - 4.2 自定义网络与容器间通信
  - 4.3 数据持久化：数据卷 (Volumes) 详解
  - 4.4 绑定挂载 (Bind Mounts) 与 `tmpfs`
  - 4.5 **实战项目二：** 部署 MySQL 容器并实现数据持久化
- **第5章：Docker Compose - 多容器编排**
  - 5.1 Docker Compose 介绍与安装
  - 5.2 `docker-compose.yml` 文件语法详解 (version, services, networks, volumes)
  - 5.3 **实战项目三：** 使用 Docker Compose 一键部署 "Spring Boot + MySQL + Redis" 应用栈
  - 5.4 Docker Compose 常用命令: `up`, `down`, `ps`, `logs`, `exec`
  - 5.5 课程总结与后续学习路径

------



### **第二门课：从单体到微服务 —— Spring Boot 应用重构实战**

**课程目标：** 掌握使用 Spring Boot 快速开发企业级单体应用的能力，深刻理解微服务架构的优缺点和适用场景，并亲手完成从单体到微服务的关键重构步骤。

**章节设计:**

- **第1章：Spring Boot 快速开发入门**
  - 1.1 Spring Boot 核心特性：自动配置、起步依赖、嵌入式服务器
  - 1.2 使用 Spring Initializr 创建项目
  - 1.3 构建 RESTful API：`@RestController`, `@GetMapping`, `@PostMapping` 等
  - 1.4 Spring Boot 配置文件详解 (`application.yml`)
- **第2章：构建企业级单-实战**
  - 2.1 **实战项目启动：** 设计并开发一个包含用户、商品、订单模块的单体电商应用
  - 2.2 整合数据访问层：MyBatis Plus (或 JPA)
  - 2.3 整合缓存：Spring Cache 与 Redis
  - 2.4 整合消息队列：RabbitMQ (或 Kafka) 实现异步下单
  - 2.5 API 文档生成：集成 SpringDoc (OpenAPI 3)
- **第3章：微服务架构理论与设计原则**
  - 3.1 单体应用的困境：技术债务、部署困难、扩展性差
  - 3.2 微服务核心思想与优势
  - 3.3 服务拆分原则：领域驱动设计 (DDD) 简介
  - 3.4 微服务间的通信方式：同步 vs 异步
  - 3.5 分布式事务挑战与解决方案简介 (Saga, TCC)
- **第4章：单体应用拆分实战**
  - 4.1 **实战项目重构：** 规划服务边界，拆分“用户服务”和“商品服务”
  - 4.2 创建用户微服务项目
  - 4.3 创建商品微服务项目
  - 4.4 使用 RestTemplate/WebClient 实现服务间的同步调用
  - 4.5 使用 OpenFeign 实现声明式服务调用
  - 4.6 拆分后遇到的新问题：服务地址硬编码、配置分散等

------



### **第三门课：微服务治理核心 —— Spring Cloud Alibaba 全家桶精讲**



**课程目标：** 系统掌握 Spring Cloud Alibaba (当前主流) 的核心组件，解决微服务架构中的服务发现、配置管理、负载均衡、服务容错、网关等关键问题，构建一个稳定、可靠的微服务体系。

**章节设计:**

- **第1章：服务注册与发现 - Nacos Discovery**
  - 1.1 为什么需要服务注册中心？
  - 1.2 Nacos Server 的安装与启动
  - 1.3 **实战：** 将用户和商品微服务注册到 Nacos
  - 1.4 Nacos 服务发现原理与心跳机制
  - 1.5 集成 Ribbon/LoadBalancer 实现客户端负载均衡
- **第2章：统一配置管理 - Nacos Config**
  - 2.1 为什么需要配置中心？
  - 2.2 **实战：** 将微服务配置迁移到 Nacos
  - 2.3 实现配置的动态刷新 (`@RefreshScope`)
  - 2.4 Nacos 配置的多环境管理 (dev, test, prod)
  - 2.5 配置的共享与优先级
- **第3章：服务容错保护 - Sentinel**
  - 3.1 分布式系统的雪崩效应
  - 3.2 Sentinel 核心概念：资源、流控、熔断、降级
  - 3.3 Sentinel Dashboard 的安装与使用
  - 3.4 **实战：** 为服务接口配置流控和熔断规则
  - 3.5 Sentinel 与 OpenFeign 的整合
  - 3.6 热点参数限流
- **第4章：统一 API 入口 - Spring Cloud Gateway**
  - 4.1 为什么需要 API 网关？
  - 4.2 Spring Cloud Gateway 核心概念：Route, Predicate, Filter
  - 4.3 **实战：** 创建 Gateway 服务，统一代理后端微服务
  - 4.4 实现动态路由（与 Nacos 结合）
  - 4.5 全局过滤器 (GlobalFilter) 实现统一认证和日志记录
  - 4.6 跨域问题处理
- **第5章：分布式事务 - Seata (选讲)**
  - 5.1 Seata 介绍与 AT 模式原理
  - 5.2 **实战：** 使用 Seata 解决跨服务的下单扣库存问题
  - 5.3 课程总结：构建完整的 Spring Cloud Alibaba 微服务架构图

------



### **第四门课：生产级部署与编排 —— Kubernetes (K8s) 实战**



**课程目标：** 带领学员从零开始进入 K8s 的世界，掌握其核心概念和资源对象，并能使用 YAML 将前面构建的微服务应用熟练地部署到 K8s 集群中，实现自动化运维。

**章节设计:**

- **第1章：Kubernetes 简介与环境搭建**
  - 1.1 为什么 Docker 之后还需要 K8s？容器编排的价值
  - 1.2 K8s 核心架构：Master (Control Plane) 与 Node
  - 1.3 搭建本地 K8s 环境：Minikube 或 Docker Desktop
  - 1.4 `kubectl` 命令行入门与自动补全配置
- **第2章：K8s 核心资源对象 (上)**
  - 2.1 Pod：K8s 的原子部署单元
  - 2.2 Label 和 Selector：资源对象的标签管理
  - 2.3 Deployment：应用部署、升级与回滚的控制器
  - 2.4 **实战：** 编写 YAML 文件，部署第一个 Nginx 应用
  - 2.5 Service：集群内部的服务发现与负载均衡 (ClusterIP)
- **第3章：K8s 核心资源对象 (下)**
  - 3.1 Service 的类型：NodePort 和 LoadBalancer
  - 3.2 ConfigMap 和 Secret：应用配置与敏感数据管理
  - 3.3 Namespace：集群的逻辑隔离
  - 3.4 Ingress：将服务暴露到集群外部的七层代理
  - 3.5 **实战：** 部署 Ingress Controller (Nginx)，并通过域名访问服务
- **第4章：高级特性与应用管理**
  - 4.1 健康检查：Liveness Probe 和 Readiness Probe
  - 4.2 资源请求与限制 (Requests & Limits)
  - 4.3 持久化存储：PersistentVolume (PV) 和 PersistentVolumeClaim (PVC)
  - 4.4 **实战：** 在 K8s 中部署有状态应用 MySQL
  - 4.5 StatefulSet：为有状态应用设计的控制器
- **第5章：将微服务项目部署到 K8s**
  - 5.1 **终极实战：** 为课程项目的每个微服务（用户、商品、网关、Nacos）编写 K8s部署 YAML
  - 5.2 水平自动伸缩 (Horizontal Pod Autoscaler - HPA)
  - 5.3 Helm：K8s 的包管理器 (简介)
  - 5.4 课程总结：云原生时代的研发运维流程

------



### **第五门课：CI/CD与自动化运维：基于Jenkins/GitLab的微服务发布**



**课程时长：** 建议 18-22 课时

**课程目标：** 打通从代码提交到应用上线的“最后一公里”，掌握 CI/CD 核心理念，并使用 Jenkins 或 GitLab CI/CD 构建一套完整的、自动化的微服务发布流水线。

**章节设计:**

- **第1章：CI/CD 核心理念与工具**
  - 1.1 什么是持续集成 (CI)、持续交付 (CD)、持续部署 (CD)？
  - 1.2 CI/CD 的价值：提升质量、加速交付
  - 1.3 主流 CI/CD 工具对比：Jenkins vs. GitLab CI vs. GitHub Actions
  - 1.4 Git 工作流简介 (Git Flow / GitHub Flow)
- **第2章：Jenkins 入门与核心配置**
  - 2.1 使用 Docker 快速部署 Jenkins
  - 2.2 Jenkins 全局工具配置 (JDK, Maven, Git)
  - 2.3 Jenkins 插件管理
  - 2.4 创建第一个 Freestyle 项目：拉取代码、编译、打包
- **第3章：Jenkins Pipeline as Code**
  - 3.1 为什么需要 Pipeline？
  - 3.2 Jenkinsfile 语法入门 (Declarative Pipeline)
  - 3.3 **实战一：** 编写 Jenkinsfile，实现 Spring Boot 应用的自动化构建和镜像打包
  - 3.4 将 Docker 镜像推送到私有仓库 (Harbor)
  - 3.5 参数化构建与凭证管理
- **第4章：构建完整的微服务 CI/CD 流水线**
  - 4.1 **实战二：** 设计并实现将微服务自动部署到 K8s 的流水线
  - 4.2 在 Jenkins Pipeline 中集成 `kubectl`
  - 4.3 实现开发分支自动部署到测试环境
  - 4.4 实现 master 分支手动确认部署到生产环境
  - 4.5 流水线中的消息通知 (邮件/钉钉/企业微信)
- **第5章：GitLab CI/CD 实战 (可选，可与 Jenkins 二选一或都讲)**
  - 5.1 GitLab CI/CD 核心概念 (`.gitlab-ci.yml`, Runner, Stages, Jobs)
  - 5.2 搭建 GitLab Runner
  - 5.3 **实战三：** 编写 `.gitlab-ci.yml` 实现与 Jenkins 同样功能的流水线
  - 5.4 GitLab CI/CD 的优势：与代码仓库的深度集成

------



### **第六门课：全方位可观测性 —— ELK 日志系统与 APM 链路追踪**



**课程目标：** 掌握构建微服务“可观测性”系统的核心技术，学会使用 ELK 搭建集中式日志平台，使用 SkyWalking 实施分布式链路追踪，从而具备快速发现、定位和解决线上问题的能力。

**章节设计:**

- **第1章：可观测性 (Observability) 导论**
  - 1.1 监控 (Monitoring) vs 可观测性 (Observability)
  - 1.2 可观测性三大支柱：日志 (Logging), 指标 (Metrics), 追踪 (Tracing)
  - 1.3 课程技术栈概览：ELK/EFK, SkyWalking, Prometheus
- **第2章：集中式日志平台 - ELK Stack**
  - 2.1 ELK 架构与组件详解 (Elasticsearch, Logstash, Kibana)
  - 2.2 **实战一：** 使用 Docker Compose 快速搭建 ELK 环境
  - 2.3 Spring Boot 应用日志改造：集成 Logback，输出 JSON 格式日志
  - 2.4 使用 Logstash 采集、过滤、处理日志并存入 Elasticsearch
  - 2.5 Kibana 可视化：创建索引模式、查询日志、制作仪表盘
- **第3章：Kubernetes 环境下的日志采集 - EFK**
  - 3.1 在 K8s 中采集日志的挑战
  - 3.2 Filebeat 介绍与工作原理
  - 3.3 **实战二：** 使用 DaemonSet 在 K8s 中部署 Filebeat
  - 3.4 将采集到的容器日志发送到 Elasticsearch 或 Logstash
  - 3.5 EFK (Elasticsearch, Fluentd, Kibana) 架构简介
- **第4章：分布式链路追踪 - SkyWalking**
  - 4.1 为什么微服务需要链路追踪？(Trace, Span, Segment)
  - 4.2 OpenTracing/OpenTelemetry 标准简介
  - 4.3 SkyWalking 架构与部署
  - 4.4 **实战三：** 为 Spring Cloud 微服务体系无侵入式集成 SkyWalking Agent
  - 4.5 SkyWalking UI 导览：服务拓扑图、端点分析、追踪查询
- **第5章：问题排查与性能分析实战**
  - 5.1 **综合实战：** 模拟一个慢接口调用，在 SkyWalking 中定位性能瓶颈
  - 5.2 **综合实战：** 模拟一个业务异常，结合 SkyWalking 的 TraceID 和 Kibana 的日志快速定位错误根源
  - 5.3 指标监控简介：Prometheus + Grafana (概念与演示)
  - 5.4 课程总结与展望：构建完整的云原生运维体系

这是一份可以直接用于教学的 Markdown 格式课程文档。它包含了详细的理论讲解、清晰的实战步骤、完整的代码示例和关键命令，结构完整，逻辑清晰。

------



# **第一门课：云原生基石 —— Docker 容器化技术详解**





## **课程信息**



- **课程名称：** 云原生基石 —— Docker 容器化技术详解

  

## **课程概述 (Course Overview)**



欢迎来到云原生微服务系列课程的第一站！本课程是整个技术体系的基石。我们将深入探索当今最核心的容器化技术——Docker。通过本课程，您将从零开始，理解容器化的革命性思想，并熟练掌握 Docker 的核心操作。我们将通过一系列层层递进的实战，最终能够将任何应用程序“装箱”打包，实现“一次构建，处处运行”的现代化开发与部署流程，为后续学习 Kubernetes 和微服务部署打下坚不可摧的基础。



### **学习目标 (Learning Objectives)**



学完本课程后，您将能够：

1. **阐述** 容器化与传统虚拟化的核心区别。
2. **熟练使用** Docker 核心命令管理镜像和容器。
3. **独立编写** 高效的 `Dockerfile` 来构建自定义应用镜像。
4. **掌握** Docker 的数据持久化（Volumes）和网络通信机制。
5. **使用** `Docker Compose` 编排和管理多容器的复杂应用。



### **目标学员 (Target Audience)**



- Java / Go / Python / 前端等方向的后端及全栈开发者。
- 希望转型云原生领域的运维工程师 (DevOps)。
- 对容器化、微服务技术感兴趣的在校学生或技术爱好者。



### **前置要求 (Prerequisites)**



- 熟悉基本的 Linux 命令行操作 (如 `ls`, `cd`, `mkdir`, `cat`)。
- 对 Web 应用程序有基本的了解（例如，知道什么是前端、后端、数据库）。
- 无需预先掌握任何 Docker 知识。



### **环境准备 (Environment Setup)**



请学员在上课前务必安装好以下软件，以确保课程顺利进行：

1. **Docker Desktop** (推荐)：
   - **Windows/macOS 用户**：请访问 [Docker 官方网站](https://www.docker.com/products/docker-desktop/) 下载并安装。
   - **Linux 用户**：请参考官方文档安装 [Docker Engine 和 Docker Compose](https://docs.docker.com/engine/install/)。
2. **代码编辑器**：
   - 推荐使用 **Visual Studio Code**，并安装 Docker 扩展插件。
3. **命令行终端**：
   - Windows 用户推荐使用 `Git Bash` 或 `WSL2`。
   - macOS 用户使用自带的 `Terminal` 或 `iTerm2` 即可。

------



## **第一章：初识容器化与 Docker**





### **1.1 学习目标**



- 理解软件开发中的“环境一致性”问题。
- 对比虚拟机（VM）与容器（Container）的差异。
- 了解 Docker 的核心架构。
- 成功安装 Docker 并运行第一个容器。



### **1.2 理论讲解**



- **“在我电脑上明明是好的！”** - 软件开发中最经典的难题，源于开发、测试、生产环境的差异（操作系统、依赖库、配置等）。
- **解决方案的演进：**
  1. **传统部署时代**：直接在物理机上部署，环境混乱，资源隔离性差。
  2. **虚拟机时代**：通过 Hypervisor 虚拟出完整的操作系统和硬件。
     - **优点**：环境隔离性极强。
     - **缺点**：笨重、资源开销大、启动慢。
  3. **容器化时代**：通过容器引擎直接利用宿主机的内核，实现进程级隔离。
     - **优点**：轻量、秒级启动、资源占用少、环境高度一致。
- **Docker 核心架构（C/S架构）**
  - **客户端 (Client)**：我们用来输入命令的工具，如 `docker` 命令。
  - **Docker 守护进程 (Daemon)**：运行在宿主机上的后台服务，负责真正地创建、运行、管理容器。
  - **仓库 (Registry)**：用于存储和分发 Docker 镜像的地方。默认是 Docker Hub。

| 特性     | 虚拟机 (Virtual Machine) | 容器 (Container) |
| -------- | ------------------------ | ---------------- |
| 隔离级别 | 操作系统级别             | 进程级别         |
| 资源占用 | 高 (GB级别)              | 低 (MB级别)      |
| 启动速度 | 慢 (分钟级)              | 快 (秒级)        |
| 内核     | 拥有独立的内核           | 共享宿主机内核   |
| 轻量级   | 笨重                     | 轻量             |



### **1.3 动手实战：安装并验证 Docker**



1. **安装 Docker**：根据【环境准备】章节完成安装。

2. **配置镜像加速器** (国内用户强烈推荐)：

   - 由于 Docker Hub 服务器在国外，下载镜像会很慢。我们需要配置国内的镜像源。

   - 打开 Docker Desktop -> Settings -> Docker Engine。

   - 在 JSON 配置中加入 `registry-mirrors` 字段。

     

     ```json
     {
       "builder": {
         "gc": {
           "defaultKeepStorage": "20GB",
           "enabled": true
         }
       },
       "experimental": false,
       "features": {
         "buildkit": true
       },
       "registry-mirrors": [
         "https://hub-mirror.c.163.com",
         "https://mirror.baidubce.com"
       ]
     }
     ```

   - 点击 "Apply & Restart" 保存并重启 Docker。

3. **验证安装**：

   - 打开你的终端，输入以下命令查看 Docker 版本：

     ```bash
     docker --version
     docker-compose --version
     ```

     *预期输出：* 会显示 Docker 和 Docker Compose 的版本号。

4. **运行第一个容器 `hello-world`**：

   - 这是 Docker 官方提供的一个用于验证安装是否成功的镜像。

   - 执行命令：

     ```bash
     docker run hello-world
     ```

   - *预期输出：* 终端会打印出 "Hello from Docker!" 的欢迎信息。这个过程 Docker 会：

     1. 本地检查有无 `hello-world` 镜像。
     2. 发现没有，于是从 Docker Hub (或你的加速器) 拉取 (pull) 该镜像。
     3. 使用该镜像创建一个新的容器。
     4. 运行容器，执行里面的程序，打印信息。
     5. 容器运行结束后自动退出。



### **1.4 本章小结**



我们理解了 Docker 为解决环境一致性问题而生，它比虚拟机更轻量、更高效。我们还成功安装了 Docker，并运行了第一个容器，验证了整个环境的正确性。

------



## **第二章：Docker 核心命令**





### **2.1 学习目标**



- 掌握镜像 (Image) 的搜索、拉取、查看和删除。
- 掌握容器 (Container) 的创建、运行、查看、停止和删除。
- 学会查看容器日志和进入容器内部。



### **2.2 理论讲解**



- **镜像 (Image)**：一个只读的模板，包含了运行应用程序所需的文件系统、库、依赖和代码。镜像是创建容器的基础。可以把它想象成 Java 中的 `Class`。
- **容器 (Container)**：镜像的运行实例。它是一个独立的、可执行的软件包。可以把它想象成 Java 中 `new` 出来的一个 `Object`。你可以对一个镜像创建多个容器。



### **2.3 动手实战：镜像与容器管理**



我们将以流行的 Web 服务器 Nginx 为例进行操作。

1. **镜像操作 (Image Management)**

   - **搜索镜像**：从 Docker Hub 搜索 Nginx 镜像。

     

     ```Bash
     docker search nginx
     ```

   - **拉取镜像**：从 Docker Hub 下载官方最新的 Nginx 镜像。

     

     ```Bash
     docker pull nginx
     ```

     > **提示：** 如果不指定版本号 (tag)，默认拉取 `latest` 版本。你也可以指定版本，如 `docker pull nginx:1.21`。

   - **查看本地镜像**：列出所有已经下载到本地的镜像。

     

     ```
     docker images
     ```

   - **删除本地镜像**：删除指定的镜像。

     

     ```
     # 语法: docker rmi <IMAGE_ID_OR_NAME>
     docker rmi nginx
     ```

     > **注意：** 如果有容器正在使用这个镜像，你需要先删除容器才能删除镜像。

2. **容器操作 (Container Management)**

   - **运行容器**：使用 `nginx` 镜像创建一个名为 `my-web` 的容器。

     

     ```
     # docker run [OPTIONS] IMAGE [COMMAND] [ARG...]
     docker run --name my-web -p 8080:80 -d nginx
     ```

     - `--name my-web`：给容器取一个名字，方便管理。
     - `-p 8080:80`：端口映射。将宿主机的 `8080` 端口映射到容器的 `80` 端口。这样我们就能通过访问宿主机的 8080 端口来访问 Nginx 服务了。
     - `-d`：后台运行 (Detached mode)。

   - **验证运行**：

     - 在浏览器中访问 `http://localhost:8080`，你应该能看到 Nginx 的欢迎页面。

   - **查看正在运行的容器**：

     

     ```
     docker ps
     ```

   - **查看所有容器** (包括已停止的)：

     

     ```
     docker ps -a
     ```

   - **查看容器日志**：

     

     ```
     # 语法: docker logs <CONTAINER_ID_OR_NAME>
     docker logs my-web
     # 持续跟踪日志
     docker logs -f my-web
     ```

   - **停止容器**：

     

     ```
     # 语法: docker stop <CONTAINER_ID_OR_NAME>
     docker stop my-web
     ```

   - **启动已停止的容器**：

     

     ```
     docker start my-web
     ```

   - **删除容器**：

     

     ```
     # 语法: docker rm <CONTAINER_ID_OR_NAME>
     docker rm my-web
     ```

     > **注意：** 必须先停止容器才能删除。如果想强制删除正在运行的容器，可以加 `-f` 参数：`docker rm -f my-web`。

   - **进入容器内部** (非常重要！用于调试)：

     

     ```
     # 语法: docker exec -it <CONTAINER_ID_OR_NAME> <COMMAND>
     docker exec -it my-web /bin/bash
     ```

     - `-i`：交互模式 (interactive)。
     - `-t`：分配一个伪终端 (pseudo-TTY)。
     - `/bin/bash`：进入容器后要执行的命令。
     - 进入后，你就如同进入了一个迷你的 Linux 系统，可以执行 `ls`, `cat` 等命令查看 Nginx 的文件。输入 `exit` 退出。



### **2.4 本章小结**



我们掌握了 Docker 中最核心、最常用的两类命令：镜像管理和容器管理。理解并熟练使用这些命令是进行一切 Docker 操作的基础。

------



## **第三章：Dockerfile - 构建自己的镜像**





### **3.1 学习目标**



- 理解 `Dockerfile` 的作用和基本结构。
- 掌握 `Dockerfile` 的常用指令。
- 亲手将一个 Spring Boot 应用程序打包成 Docker 镜像。
- 了解多阶段构建，优化镜像体积。



### **3.2 理论讲解**



`Dockerfile` 是一个文本文件，里面包含了一系列用于构建 Docker 镜像的指令。Docker 通过读取 `Dockerfile` 中的指令，自动完成镜像的构建过程。

**常用指令：**

- `FROM <image>:<tag>`：指定基础镜像，必须是第一条指令。
- `WORKDIR /path/to/workdir`：设置工作目录，后续的 `RUN`, `COPY`, `CMD` 指令都会在这个目录下执行。
- `COPY <src> <dest>`：将宿主机的文件或目录复制到镜像中。
- `RUN <command>`：在镜像构建过程中执行命令（例如安装依赖 `apt-get install`）。
- `CMD ["executable","param1","param2"]`：容器启动时执行的默认命令。如果 `docker run` 时指定了其他命令，`CMD` 会被覆盖。
- `ENTRYPOINT ["executable", "param1"]`：与 `CMD` 类似，但更不容易被覆盖，通常用于设置容器的主命令。
- `ENV <key>=<value>`：设置环境变量。
- `EXPOSE <port>`：声明容器运行时会监听的端口（仅作文档说明，无实际映射作用）。



### **3.3 动手实战：构建 Spring Boot 应用镜像**



**第一步：准备一个简单的 Spring Boot 应用**

- 如果学员有现成的项目最好。如果没有，可以快速创建一个。

- **创建一个 `demo` 文件夹，并在其中创建以下文件：**

  1. **`pom.xml`** (Maven 配置文件)

     

     ```xml
     <?xml version="1.0" encoding="UTF-8"?>
     <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
         <modelVersion>4.0.0</modelVersion>
         <parent>
             <groupId>org.springframework.boot</groupId>
             <artifactId>spring-boot-starter-parent</artifactId>
             <version>2.7.5</version>
             <relativePath/>
         </parent>
         <groupId>com.example</groupId>
         <artifactId>demo</artifactId>
         <version>0.0.1-SNAPSHOT</version>
         <name>demo</name>
         <properties>
             <java.version>1.8</java.version>
         </properties>
         <dependencies>
             <dependency>
                 <groupId>org.springframework.boot</groupId>
                 <artifactId>spring-boot-starter-web</artifactId>
             </dependency>
             <dependency>
                 <groupId>org.springframework.boot</groupId>
                 <artifactId>spring-boot-starter-test</artifactId>
                 <scope>test</scope>
             </dependency>
         </dependencies>
         <build>
             <plugins>
                 <plugin>
                     <groupId>org.springframework.boot</groupId>
                     <artifactId>spring-boot-maven-plugin</artifactId>
                 </plugin>
             </plugins>
         </build>
     </project>
     ```

  2. **创建目录结构 `src/main/java/com/example/demo/` 和 `src/main/java/com/example/demo/controller/`**

  3. **`src/main/java/com/example/demo/controller/HelloController.java`**
  
     ```java
      package com.example.demo.controller;
     
      import org.springframework.web.bind.annotation.GetMapping;
      import org.springframework.web.bind.annotation.RequestParam;
      import org.springframework.web.bind.annotation.RestController;
     
      @RestController
      public class HelloController {
     
          @GetMapping("/")
          public String sayHello() {
              return "Hello from Docker!";
          }
     
          @GetMapping("/hello")
          public String sayHello(@RequestParam(value = "name", defaultValue = "World") String name) {
              return String.format("Hello, %s!", name);
          }
      }
     ```
  
  4. **`src/main/resources/application.yml`**
  
     ```yaml
      server:
        port: 8081
     
      spring:
        application:
          name: demo
     ```
  
  5. **`src/main/java/com/example/demo/DemoApplication.java`**
  
     ```java
     package com.example.demo;
     
     import org.springframework.boot.SpringApplication;
     import org.springframework.boot.autoconfigure.SpringBootApplication;
     import org.springframework.web.bind.annotation.GetMapping;
     import org.springframework.web.bind.annotation.RestController;
     
     @SpringBootApplication
     public class DemoApplication {
     
         public static void main(String[] args) {
             SpringApplication.run(DemoApplication.class, args);
         }
     }
     ```
  
     

**第二步：编译并打包应用**

- 在项目根目录（`pom.xml` 所在目录）打开终端，执行 Maven 打包命令。

  

  ```bash
  # 如果你本地安装了 Maven
  mvn clean package
  
  # 可以通过mvn spring-boot:run运行，也可以轻松打包成Docker镜像
  
  # 如果没有，可以使用 Maven 的 Docker 镜像来打包
  # docker run -it --rm -v "$(pwd)":/app -w /app maven:3.8-openjdk-8 mvn clean package
  ```

- 执行成功后，你会在 `target` 目录下看到一个 `demo-0.0.1-SNAPSHOT.jar` 文件。

**第三步：编写 `Dockerfile`**

- 在项目根目录（与 `pom.xml` 同级）创建一个名为 `Dockerfile` (无后缀名) 的文件。

- 输入以下内容：

  

  ```dockerfile
  # 步骤1: 指定基础镜像，Java 应用需要 JRE 环境
  FROM openjdk:8-jre-slim
  
  # 步骤2: 设置工作目录
  WORKDIR /app
  
  # 步骤3: 将打包好的 jar 文件复制到镜像的工作目录中
  # target/demo-0.0.1-SNAPSHOT.jar 是宿主机路径
  # app.jar 是镜像内的目标文件名
  COPY target/demo-0.0.1-SNAPSHOT.jar app.jar
  
  # 步骤4: 声明容器将监听 8080 端口
  EXPOSE 8080
  
  # 步骤5: 容器启动时执行的命令
  # 等同于在终端执行: java -jar app.jar
  ENTRYPOINT ["java", "-jar", "app.jar"]
  ```

**第四步：构建镜像**

- 在 `Dockerfile` 所在目录打开终端，执行构建命令。

  

  ```bash
  # 语法: docker build -t <repository>:<tag> <path_to_dockerfile>
  docker build -t my-spring-app:1.0 .
  ```

  - `-t my-spring-app:1.0`：给镜像命名并打上标签。
  - `.`：表示 Dockerfile 在当前目录下。

- 构建成功后，使用 `docker images` 命令可以看到你新创建的镜像。

**第五步：运行你的应用镜像**

- Bash`  docker run --name my-app-container -p 8080:8080 -d my-spring-app:1.0 `
- 在浏览器中访问 `http://localhost:8080`，你应该能看到 "Hello from Docker!"。



### **3.4 本章小结**



我们学会了 Docker 最具创造力的部分——使用 `Dockerfile` 定义和构建自己的应用镜像。同时，我们还掌握了多阶段构建这一高级技巧，来优化我们的镜像，使其更适合在生产环境中使用。

------



## **第四章：Docker 数据持久化与网络**





### **4.1 学习目标**



- 理解容器文件系统的“易失性”。
- 使用数据卷 (Volumes) 实现数据的持久化。
- 理解 Docker 的网络模式，并实现容器间通信。



### **4.2 理论讲解**



- **数据持久化**
  - **问题**：容器被删除后，其内部产生的所有数据都会丢失。这对于像数据库这样的应用是无法接受的。
  - **解决方案：数据卷 (Volumes)**。Volume 是由 Docker 管理的、独立于容器生命周期的宿主机上的一个特殊目录。即使容器被删除，Volume 及其中的数据依然存在。
- **Docker 网络**
  - **Bridge (默认)**：Docker 会创建一个虚拟网桥，所有容器默认连接到这个网桥上，形成一个独立的内部网络。容器间可以通过 IP 地址通信，但 Docker 不保证 IP 地址不变。
  - **Host**：容器共享宿主机的网络，没有网络隔离。性能高，但安全性差。
  - **None**：容器没有网络连接。
  - **自定义网络 (User-defined Bridge Network)**：推荐做法！在自定义网络中的容器，可以通过**容器名**作为 DNS 主机名进行互相访问，非常方便。



### **4.3 动手实战：部署持久化的 MySQL 并连接**



**第一步：使用数据卷部署 MySQL**

1. **创建数据卷**：

   ```
   docker volume create mysql-data
   ```
   
2. **查看数据卷**：

   ```
   docker volume ls
   ```
   
3. **运行 MySQL 容器**：

   ```
   docker run --name my-mysql \
     -v mysql-data:/var/lib/mysql \
     -p 3306:3306 \
     -e MYSQL_ROOT_PASSWORD=my-secret-pw \
     -d mysql:5.7
   ```
   
   - `-v mysql-data:/var/lib/mysql`：将我们刚创建的 `mysql-data` 数据卷挂载到容器内 MySQL 存放数据的标准目录 `/var/lib/mysql`。
- `-e MYSQL_ROOT_PASSWORD=...`：通过环境变量设置 MySQL 的 root 用户密码。

**第二步：验证数据持久化**

1. 进入 MySQL 容器，创建一个数据库。

   ```
   docker exec -it my-mysql mysql -uroot -pmy-secret-pw
   # 在 MySQL 命令行中执行:
   CREATE DATABASE test_db;
   SHOW DATABASES;
   exit;
   ```
   
2. 删除 MySQL 容器。

   ```
   docker stop my-mysql
   docker rm my-mysql
   ```
   
3. 重新创建一个同名容器，并挂载同一个数据卷。

   ```
   docker run --name my-mysql -v mysql-data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:5.7
   ```
   
4. 再次进入新容器，查看数据库。

   ```
   docker exec -it my-mysql mysql -uroot -pmy-secret-pw
   # 在 MySQL 命令行中执行:
   SHOW DATABASES;
   exit;
   ```
   
   - *预期结果：* 你会发现 `test_db` 依然存在！这证明了数据卷成功地持久化了我们的数据。

**第三步：容器间通信**

1. **创建自定义网络**：

   ```
   docker network create my-app-net
   ```
   
2. **停止并删除之前创建的所有容器**，保持环境干净。

   ```
   # 确保之前的 my-mysql 和 my-app-container 都被删除了
   docker stop my-mysql my-app-container
   docker rm my-mysql my-app-container
   ```
   
3. **将 MySQL 连接到新网络中运行**：

   ```
docker run --name my-mysql \
     --network my-app-net \
     -v mysql-data:/var/lib/mysql \
     -e MYSQL_ROOT_PASSWORD=my-secret-pw \
     -d mysql:5.7
   ```
   
   - 新增了 `--network my-app-net` 参数。

4. **将我们的 Spring Boot 应用也连接到该网络**：

   > **注意：** 为了让 Spring Boot 连接数据库，我们需要修改应用代码或配置。这里为了演示方便，我们只演示网络连通性。

   ```
   docker run --name my-app-container \
     --network my-app-net \
     -d my-spring-app:2.0
   ```
   
5. **验证网络通信**：

   - 进入 `my-app-container` 容器内部。

     ```
     docker exec -it my-app-container /bin/bash
     ```
     
   - 在容器内，尝试 `ping` MySQL 容器（需要先安装 `ping` 工具）。

     ```
     # 更新包列表并安装 iputils-ping
     apt-get update && apt-get install -y iputils-ping
     
     # 使用容器名作为主机名进行 ping
     ping my-mysql
     ```
     
   - *预期结果：* 你会看到 `ping` 命令成功返回，证明了应用容器可以通过容器名 `my-mysql` 访问到数据库容器。



### **4.4 本章小结**

我们解决了容器数据持久化的关键问题，并学会了如何组织容器网络，让多个容器之间可以像在同一个局域网内一样方便地互相通信。这是部署复杂应用的基础。

------



## **第五章：Docker Compose - 多容器编排**



### **5.1 学习目标**

- 理解为什么需要 Docker Compose。
- 掌握 `docker-compose.yml` 文件的核心语法。
- 使用 Docker Compose 一键式部署和管理整个应用栈。



### **5.2 理论讲解**



- **痛点**：当我们的应用由多个服务（如 Web后端、数据库、缓存、消息队列）组成时，需要为每个服务执行一长串的 `docker run` 命令，并且需要手动管理它们之间的网络、依赖关系，非常繁琐且容易出错。
- **Docker Compose**：是 Docker 官方的开源项目，用于定义和运行多容器 Docker 应用程序。通过一个单独的 `docker-compose.yml` 配置文件，就可以配置应用的所有服务，然后使用一条命令，就可以根据配置创建并启动所有服务。



### **5.3 动手实战：使用 Compose 部署完整应用栈**



我们将部署一个由三个服务组成的经典应用：

1. **app**: 我们的 Spring Boot 应用。
2. **db**: MySQL 数据库。
3. **redis**: Redis 缓存。

**第一步：创建 `docker-compose.yml` 文件**

- 在你的 Spring Boot 项目根目录下，创建一个名为 `docker-compose.yml` 的文件。

- 输入以下内容：

  

  ```yaml
  # Compose 文件版本号
  version: '3.8'
  
  # 定义所有服务
  services:
    # 定义 app 服务
    app:
      # 使用我们之前构建的镜像
      image: my-spring-app:2.0
      # 如果镜像不存在，也可以直接在这里构建
      # build: .
      container_name: compose-app
      # 端口映射
      ports:
        - "8080:8080"
      # 依赖关系，确保 db 和 redis 先于 app 启动
      depends_on:
        - db
        - redis
      # 环境变量，可以用来配置数据库连接等 (需要在 Spring Boot 中读取)
      environment:
        - SPRING_DATASOURCE_URL=jdbc:mysql://db:3306/mydatabase?useSSL=false
        - SPRING_DATASOURCE_USERNAME=root
        - SPRING_DATASOURCE_PASSWORD=my-secret-pw
        - SPRING_REDIS_HOST=redis
  
    # 定义 db 服务
    db:
      image: mysql:5.7
      container_name: compose-mysql
      # 数据卷挂载，这里直接使用 docker-compose 管理的匿名卷
      volumes:
        - db_data:/var/lib/mysql
      # 环境变量
      environment:
        - MYSQL_ROOT_PASSWORD=my-secret-pw
        - MYSQL_DATABASE=mydatabase
  
    # 定义 redis 服务
    redis:
      image: redis:6-alpine
      container_name: compose-redis
  
  # 定义数据卷
  volumes:
    db_data:
  ```

**第二步：使用 Compose 命令管理应用**

- 在 `docker-compose.yml` 文件所在目录打开终端。

1. **后台启动所有服务**：

   

   ```
   docker-compose up -d
   ```

   - Compose 会自动创建网络，并按 `depends_on` 的顺序启动所有服务。

2. **查看服务状态**：

   

   ```
   docker-compose ps
   ```

3. **查看服务日志**：

   

   ```
   # 查看所有服务的日志
   docker-compose logs
   # 查看特定服务的日志并持续跟踪
   docker-compose logs -f app
   ```

4. **停止并删除所有服务**：

   

   ```
   docker-compose down
   ```

   > **提示：** `down` 命令会删除容器和网络，但默认会保留数据卷。如果想同时删除数据卷，可以添加 `-v` 参数：`docker-compose down -v`。



### **5.4 本章小结**



我们学会了使用 Docker Compose 这一强大的工具，将复杂的多服务应用配置抽象为一个简单的 YAML 文件，实现了“一键启动，一键销毁”的开发环境管理。这极大地提升了我们的开发和测试效率。

------



## **课程总结与展望**



通过这门课程的学习，你已经：

- **掌握了 Docker 的核心理念与全部常用操作。**
- **具备了将任何应用容器化的能力。**
- **能够使用 Docker Compose 搭建完整的本地开发测试环境。**

你已经成功迈出了云原生之旅的第一步，并为后续更精彩的课程打下了坚实的基础。

**下一步学什么？**

- **《第二门课：从单体到微服务 —— Spring Boot 应用重构实战》**：我们将利用今天学到的知识，开始构建我们的核心业务应用。
- **《第四门课：生产级部署与编排 —— Kubernetes (K8s) 实战》**：当你需要将成百上千个容器部署到生产环境集群时，Kubernetes 将是你的终极武器。



好的，我们继续。

这是《第二门课：从单体到微服务 —— Spring Boot 应用重构实战》的完整教学文档。它承接了第一门 Docker 课程，将带领学员进入业务开发的核心，并亲身体验从传统单体架构演进到现代微服务架构的完整过程。

------



# **第二门课：从单体到微服务 —— Spring Boot 应用重构实战**



## **课程信息**



- **课程名称：** 从单体到微服务 —— Spring Boot 应用重构实战



## **课程概述 (Course Overview)**



欢迎来到云原生微服务系列课程的第二站！在本课程中，我们将聚焦于现代 Java 开发的核心框架——Spring Boot。我们将首先利用其强大的快速开发能力，从零开始构建一个功能完备的企业级单体应用（Monolith）。随后，我们将深入探讨微服务架构的理论精髓，分析单体架构在复杂业务场景下的瓶颈。本课程最大的亮点在于，您将亲自动手，遵循业界标准的重构原则，将我们共同构建的单体应用逐步拆分为多个职责单一、可独立部署的微服务（Microservices），为迈向真正的分布式系统打下坚实的基础。



### **学习目标 (Learning Objectives)**



学完本课程后，您将能够：

1. **熟练使用** Spring Boot 快速构建 RESTful API 和企业级 Web 应用。
2. **掌握** 整合常用中间件（如 MySQL, Redis, RabbitMQ）的实战技巧。
3. **深刻理解** 微服务架构的核心思想、优势以及它所带来的挑战。
4. **掌握** 服务拆分的基本原则和领域驱动设计（DDD）的初步概念。
5. **具备** 将一个现有单体应用重构为微服务架构的实践能力。



### **目标学员 (Target Audience)**



- 具备 Java 基础的开发者。
- 希望系统学习 Spring Boot 并 transitioning to 微服务架构的 Java 工程师。
- 了解后端开发，希望了解现代应用架构演进过程的技术人员。



### **前置要求 (Prerequisites)**



- **必须**：完成 **《第一门课：云原生基石 —— Docker 容器化技术详解》** 或具备同等的 Docker 知识。
- **必须**：具备扎实的 Java 语言基础 (面向对象、集合、IO、多线程等)。
- **推荐**：了解 Spring 框架的基本概念 (IoC, AOP)。
- **推荐**：了解 Maven 或 Gradle 等构建工具。
- **推荐**：了解基本的数据库 SQL 操作。



### **环境准备 (Environment Setup)**



1. **JDK**：Java Development Kit 1.8 或更高版本 (推荐 1.8 或 11)。
2. **IDE**：IntelliJ IDEA (Community 或 Ultimate 版均可) 或 Eclipse。
3. **构建工具**：Apache Maven 3.6+。
4. **数据库**：本地安装 MySQL 5.7+，或使用 Docker 启动一个 MySQL 实例。
5. **Docker & Docker Compose**：确保已安装并可正常运行 (承接第一门课)。
6. **API 测试工具**：Postman 或 Insomnia。

------



## **第一章：Spring Boot 快速开发入门**





### **1.1 学习目标**



- 理解 Spring Boot 的核心特性。
- 使用 Spring Initializr 快速创建和配置项目。
- 构建第一个 RESTful API。
- 掌握 `application.yml` 配置文件的使用。



### **1.2 理论讲解**



- **Spring Boot 是什么？**
  - 它不是一个新技术，而是对 Spring 框架的“脚手架”和“自动化增强”。
  - **核心思想：** 约定大于配置 (Convention over Configuration)。
- **核心特性：**
  1. **起步依赖 (Starters)**：简化的依赖管理。例如，`spring-boot-starter-web` 会自动引入所有 Web 开发所需的依赖（Tomcat, Spring MVC 等）。
  2. **自动配置 (Auto-configuration)**：根据你添加的依赖，智能地配置 Spring Bean。例如，只要引入了数据库驱动和 `spring-boot-starter-jdbc`，它就会自动配置一个数据源 (DataSource)。
  3. **嵌入式服务器**：无需部署 WAR 包到外部 Tomcat，直接打包成一个可执行的 JAR 文件，内置了 Tomcat (或 Jetty, Undertow)。
  4. **健康检查与监控 (Actuator)**：提供生产级的应用监控端点。



### **1.3 动手实战：Hello Spring Boot**



1. **使用 Spring Initializr 创建项目**

   - 打开浏览器，访问 `https://start.spring.io`。
   - **项目配置：**
     - Project: `Maven Project`
     - Language: `Java`
     - Spring Boot: `2.7.x` (选择一个稳定的版本)
     - Project Metadata:
       - Group: `com.example`
       - Artifact: `monolith-app`
       - Packaging: `Jar`
       - Java: `8` or `11`
   - **添加依赖 (Dependencies)：**
     - `Spring Web`: 用于构建 Web 应用和 RESTful API。
     - `Lombok`: 简化 JavaBean 开发，自动生成 Getter/Setter 等。
   - 点击 "GENERATE"，下载项目压缩包并解压，用 IDEA 打开。

2. **编写第一个 Controller**

   - 在 `com.example.monolithapp` 包下创建一个新的 `controller` 包。

   - 在 `controller` 包下创建 `HelloController.java` 文件：

     

     ```java
     package com.example.monolithapp.controller;
     
     import org.springframework.web.bind.annotation.GetMapping;
     import org.springframework.web.bind.annotation.RequestParam;
     import org.springframework.web.bind.annotation.RestController;
     
     @RestController
     public class HelloController {
     
         @GetMapping("/hello")
         public String sayHello(@RequestParam(value = "name", defaultValue = "World") String name) {
             return String.format("Hello, %s!", name);
         }
     }
     ```

3. **运行与测试**

   - 运行 `MonolithAppApplication.java` 的 `main` 方法。
   - 打开 Postman 或浏览器，访问 `http://localhost:8080/hello` 和 `http://localhost:8080/hello?name=Spring Boot`。

4. **配置文件 `application.yml`**

   - Spring Boot 默认使用 `application.properties`。我们通常更喜欢 YAML 格式，因为它层次更清晰。

   - 将 `src/main/resources/application.properties` 重命名为 `application.yml`。

   - 修改端口号示例：

     

     ```yaml
     server:
       port: 8081
     ```

   - 重新启动应用，现在需要访问 `http://localhost:8081/hello`。



### **1.4 本章小结**



我们快速体验了 Spring Boot 的开发流程，理解了它的核心优势，并成功构建和运行了一个简单的 Web 应用。

------



## **第二章：构建企业级单体应用-实战**





### **2.1 学习目标**



- 设计一个包含多模块的单体应用。
- 集成 MyBatis Plus 实现数据持久化。
- 集成 Redis 实现缓存。
- 集成 RabbitMQ 实现异步处理。



### **2.2 理论讲解**



- **单体架构 (Monolithic Architecture)**
  - 所有功能模块（用户、商品、订单等）都打包在同一个应用程序中，作为一个单元进行开发、部署和扩展。
  - **优点**：开发简单、测试方便、易于部署。
  - **缺点**：随着业务复杂化，代码耦合度高、构建时间长、技术栈单一、不利于扩展。
- **项目分层结构 (Layered Architecture)**
  - **Controller Layer**：接收 HTTP 请求，调用 Service，返回响应。
  - **Service Layer**：处理核心业务逻辑。
  - **Repository/DAO Layer**：与数据库交互，进行数据持久化操作。
  - **Domain/Entity Layer**：定义数据模型。



### **2.3 动手实战：构建电商单体应用**



**项目设定：** 一个完整的电商系统，包含 **用户管理**、**商品管理**、**Redis缓存集成**、**RabbitMQ消息队列** 和 **API文档生成** 等完整企业级功能。

#### 项目概览

我们已成功构建了一个功能完备的电商单体应用，具有以下核心特性：

- **技术栈**：Spring Boot 2.7.5 + MyBatis Plus 3.5.2 + MySQL 5.7 + Redis 6-alpine + RabbitMQ 3-management + SpringDoc OpenAPI
- **项目结构**：采用标准的分层架构，包含 Controller、Service、Mapper、Entity、Config、Common 等完整模块
- **核心功能**：用户CRUD管理、商品CRUD管理、Redis缓存集成、RabbitMQ消息队列、API文档生成、全局异常处理
- **部署方式**：支持Docker容器化部署，包含完整的环境配置和数据库脚本

1. **添加依赖**

   - 在 `pom.xml` 中加入以下 `starter`：



     ```xml
     <!-- MyBatis Plus 数据持久化 -->
     <dependency>
         <groupId>com.baomidou</groupId>
         <artifactId>mybatis-plus-boot-starter</artifactId>
         <version>3.5.2</version>
     </dependency>
    
     <!-- MySQL 数据库连接 -->
     <dependency>
         <groupId>mysql</groupId>
         <artifactId>mysql-connector-java</artifactId>
         <scope>runtime</scope>
     </dependency>
    
     <!-- Redis 缓存 -->
     <dependency>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-data-redis</artifactId>
     </dependency>
    
     <!-- RabbitMQ 消息队列 -->
     <dependency>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-amqp</artifactId>
     </dependency>
     <dependency>
         <groupId>org.springdoc</groupId>
         <artifactId>springdoc-openapi-ui</artifactId>
         <version>1.6.12</version>
     </dependency>
    
     <!-- Lombok 简化开发 -->
     <dependency>
         <groupId>org.projectlombok</groupId>
         <artifactId>lombok</artifactId>
         <optional>true</optional>
     </dependency>
     ```

2. **配置 `application.yml`**

   

   ```yaml
   server:
     port: 8080
   
   spring:
     datasource:
       url: jdbc:mysql://localhost:3306/monolith_db?useSSL=false&serverTimezone=UTC
       username: root
       password: your_password # 替换为你的密码
       driver-class-name: com.mysql.cj.jdbc.Driver
     redis:
       host: localhost
       port: 6379
     rabbitmq:
       host: localhost
       port: 5672
       username: guest
       password: guest
   
   mybatis-plus:
     mapper-locations: classpath:/mapper/*.xml
     global-config:
       db-config:
         logic-delete-field: deleted # 全局逻辑删除字段
   ```

3. **创建数据库实体 (Entity)**

   - **用户实体** (`User.java`)：

     ```java
     @Data
     @TableName("users")
     public class User {
         @TableId(type = IdType.AUTO)
         private Long id;
         private String username;
         private String password;
         private String email;
         @TableField(value = "created_time", fill = FieldFill.INSERT)
         private String createdTime;
         @TableField(value = "updated_time", fill = FieldFill.INSERT_UPDATE)
         private String updatedTime;
         @TableLogic
         private Integer deleted;
     }
     ```

   - **商品实体** (`Product.java`)：

     ```java
     @Data
     @TableName("products")
     public class Product {
         @TableId(type = IdType.AUTO)
         private Long id;
         private String name;
         private String description;
         private BigDecimal price;
         private Integer stock;
         private Long categoryId;
         private Long brandId;
         @TableField(value = "created_time", fill = FieldFill.INSERT)
         private String createdTime;
         @TableField(value = "updated_time", fill = FieldFill.INSERT_UPDATE)
         private String updatedTime;
         @TableLogic
         private Integer deleted;
     }
     ```

4. **创建数据访问层 (Mapper)**

   - **用户Mapper** (`UserMapper.java`)：

     ```java
     @Repository
     public interface UserMapper extends BaseMapper<User> {
     }
     ```

   - **商品Mapper** (`ProductMapper.java`)：

     ```java
     @Repository
     public interface ProductMapper extends BaseMapper<Product> {
     }
     ```

5. **实现服务层 (Service)**

   - **用户服务接口** (`UserService.java`)：

     ```java
     @Service
     public class UserServiceImpl implements UserService {
         @Autowired
         private UserMapper userMapper;
  
         @Override
         public Result<User> getUserById(Long id) {
             User user = userMapper.selectById(id);
             return Result.success(user);
         }
  
         @Override
         public Result<List<User>> getAllUsers() {
             List<User> users = userMapper.selectList(null);
             return Result.success(users);
         }
  
         @Override
         @CacheEvict(value = "users", key = "#user.id")
         public Result<User> updateUser(User user) {
             userMapper.updateById(user);
             return Result.success(user);
         }
     }
     ```

7. **实现商品模块 (Product Module)** - 步骤同用户模块

8. **集成 Redis 缓存**

   - 在主启动类上添加 `@EnableCaching` 注解。

   - 在 `UserService` 的查询方法上添加 `@Cacheable` 注解。

     

     ```java
     @Cacheable(value = "users", key = "#id")
     public User getUserById(Long id) {
         // ... 方法体
     }
     ```

   - 测试：第一次查询会访问数据库，后续查询会直接从 Redis 返回。

9. **实现 Controller 层**

   - **用户控制器** (`UserController.java`)：

     ```java
     @RestController
     @RequestMapping("/users")
     public class UserController {
         @Autowired
         private UserService userService;
  
         @PostMapping
         public Result<User> createUser(@RequestBody User user) {
             userService.save(user);
             return Result.success(user);
         }
  
         @GetMapping("/{id}")
         @Cacheable(value = "users", key = "#id")
         public Result<User> getUserById(@PathVariable Long id) {
             return userService.getUserById(id);
         }
  
         @GetMapping
         public Result<List<User>> getAllUsers() {
             return userService.getAllUsers();
         }
  
         @PutMapping("/{id}")
         @CacheEvict(value = "users", key = "#id")
         public Result<User> updateUser(@PathVariable Long id, @RequestBody User user) {
             user.setId(id);
             userService.updateById(user);
             return Result.success(user);
         }
  
         @DeleteMapping("/{id}")
         @CacheEvict(value = "users", key = "#id")
         public Result<Void> deleteUser(@PathVariable Long id) {
             userService.removeById(id);
             return Result.success();
         }
     }
     ```

10. **API 文档**

   - 启动应用后，访问 `http://localhost:8080/swagger-ui.html` 即可看到自动生成的 API 文档。



### **2.4 本章小结**



我们从零开始，构建了一个功能齐全、结构清晰的单体应用。这个过程让我们对 Spring Boot 的整合能力有了深入的了解。同时，这个单体应用将是我们下一章进行微服务重构的"原材料"。

#### 关键实现要点

1. **统一的响应格式**：使用 `Result<T>` 统一API响应格式
2. **全局异常处理**：通过 `@ControllerAdvice` 统一处理异常
3. **Redis缓存集成**：使用 `@Cacheable`、`@CacheEvict` 等注解实现缓存管理
4. **数据库设计**：采用UTF-8编码，支持中文，包含逻辑删除功能
5. **API文档**：集成SpringDoc OpenAPI，自动生成Swagger文档
6. **分层架构**：清晰的Controller-Service-Mapper-Entity分层结构
7. **Docker支持**：完整的Docker部署方案，包含数据库初始化脚本

------



## **第三章：微服务架构理论与设计原则**





### **3.1 学习目标**



- 理解从单体到微服务的驱动力。
- 掌握微服务架构的核心思想和设计原则。
- 了解服务拆分的常见策略和模式。
- 认识微服务架构带来的新挑战。



### **3.2 理论讲解**



- **单体应用的困境 (The Monolith's Dilemma)**
  - **敏捷性下降**：任何小改动都需要重新构建和部署整个应用。
  - **技术债累积**：代码库庞大，新人上手困难，重构风险高。
  - **扩展性受限**：只能对整个应用进行水平扩展，无法针对性地扩展高负载模块。
  - **技术栈僵化**：整个应用被绑定在单一技术栈上，难以引入新技术。
  - **可靠性问题**：任何一个模块的严重 bug 都可能导致整个应用崩溃。
- **微服务核心思想 (The Microservices Idea)**
  - 将一个大型单体应用拆分为一组小型的、独立的服务。
  - 每个服务围绕一个特定的业务能力构建。
  - 每个服务都可以独立开发、独立部署、独立扩展。
  - 服务之间通过轻量级的通信机制（通常是 HTTP RESTful API）进行协作。
- **服务拆分原则 (Principles of Service Decomposition)**
  - **单一职责原则 (Single Responsibility Principle)**：每个服务只做一件事，并把它做好。
  - **高内聚，低耦合 (High Cohesion, Low Coupling)**：服务内部的功能紧密相关，服务之间的依赖尽可能少。
  - **围绕业务能力组织 (Organized around Business Capabilities)**：服务应该代表一个业务功能，而不是一个技术分层。例如，“订单服务”而不是“订单数据库服务”。
  - **领域驱动设计 (Domain-Driven Design - DDD)**：一种强大的软件设计方法论，通过对业务领域进行建模，识别出“限界上下文 (Bounded Context)”，每个限界上下文通常可以映射为一个微服务。
- **微服务带来的新挑战 (New Challenges)**
  - **分布式系统的复杂性**：服务发现、配置管理、负载均衡、容错处理...
  - **数据一致性**：分布式事务成为一个难题。
  - **运维成本**：需要管理大量的服务，对自动化运维（DevOps）要求更高。
  - **监控和故障排查**：一个请求可能跨越多个服务，需要分布式链路追踪。
  - **接口和版本管理**：需要有良好的 API 版本控制策略。



### **3.3 本章小结**



本章是理论的升华。我们理解了为什么要走向微服务，这不仅仅是一次技术升级，更是为了应对日益复杂的业务需求和提升团队的敏捷性。理解这些理论，将指导我们在下一章进行合理且有效的服务拆分。

------



## **第四章：单体应用拆分实战**





### **4.1 学习目标**



- 规划服务的边界，制定拆分策略。
- 创建独立的微服务项目。
- 使用 `RestTemplate` 和 `OpenFeign` 实现服务间的同步调用。
- 初步感受微服务架构带来的变化。



### **4.2 动手实战：重构电商应用**



**第一步：规划服务边界**

- 根据业务能力，我们将单体应用 `monolith-app` 拆分为两个微服务：
  1. **`user-service`**：负责所有与用户相关的业务，包括注册、登录、查询等。拥有自己的用户数据库表。
  2. **`product-service`**：负责所有与商品相关的业务。拥有自己的商品数据库表。
- **思考**：如果有一个“创建订单”的功能，它需要同时调用用户服务（验证用户）和商品服务（查询商品信息、扣减库存），这将是典型的服务协作场景。

**第二步：创建微服务项目**

1. **创建 `user-service` 项目**：
   - 使用 Spring Initializr 创建一个新的 Spring Boot 项目。
   - 将 `monolith-app` 中与用户相关的代码（Entity, Mapper, Service, Controller）迁移过来。
   - 调整数据库配置，使其连接到独立的 `user_db` 数据库。
2. **创建 `product-service` 项目**：
   - 同上，迁移商品相关的代码。
   - 连接到独立的 `product_db` 数据库。

**第三步：实现服务间调用**

- **场景**：假设我们在 `product-service` 中需要获取某个商品是哪个用户发布的。商品表中存有 `userId`。我们需要根据 `userId` 去调用 `user-service` 来获取用户信息。

1. **方法一：使用 `RestTemplate`**

   - Spring 提供的传统 HTTP 客户端。

   - 需要在 `product-service` 中配置一个 `RestTemplate` Bean。

     ```java
     @Configuration
     public class RestTemplateConfig {
         @Bean
         public RestTemplate restTemplate() {
             return new RestTemplate();
         }
     }
     ```

   - 在 `ProductServiceImpl` 中注入并使用它：

     ```java
     @Service
     public class ProductServiceImpl extends ServiceImpl<ProductMapper, Product> implements ProductService {
         @Autowired
         private RestTemplate restTemplate;
     
         public ProductDTO getProductWithUser(Long productId) {
             Product product = this.getById(productId);
             // 问题：服务地址硬编码了！
             String url = "http://localhost:8081/users/" + product.getUserId();
             UserDTO user = restTemplate.getForObject(url, UserDTO.class);
     
             ProductDTO result = new ProductDTO();
             BeanUtils.copyProperties(product, result);
             result.setUser(user);
             return result;
         }
     }
     ```

   - **缺点**：URL 硬编码、代码可读性差、没有负载均衡。

2. **方法二：使用 `OpenFeign` (推荐)**

   - 一种声明式的、模板化的 HTTP 客户端。让调用远程服务像调用本地方法一样优雅。

   - 在 `product-service` 的 `pom.xml` 中添加 `spring-cloud-starter-openfeign` 依赖（注意：需要引入 Spring Cloud 的依赖管理）。

   - 在主启动类上添加 `@EnableFeignClients` 注解。

   - 创建一个 `client` 包，定义一个 `UserClient` 接口：

     ```java
     // 指定要调用的服务名，url 是服务的地址
     @FeignClient(name = "userservice", url = "http://localhost:8081")
     public interface UserClient {
     
         @GetMapping("/users/{id}")
         UserDTO findById(@PathVariable("id") Long id);
     }
     ```

   - 在 `ProductServiceImpl` 中注入 `UserClient` 并使用：

     ```java
     @Service
     public class ProductServiceImpl ... {
         @Autowired
         private UserClient userClient;
     
         public ProductDTO getProductWithUser(Long productId) {
             Product product = this.getById(productId);
             // 像调用本地方法一样调用远程服务
             UserDTO user = userClient.findById(product.getUserId());
             // ... 组装结果
         }
     }
     ```

**第四步：运行和测试**

- 分别启动 `user-service` (端口8081) 和 `product-service` (端口8082)。
- 使用 Postman 调用 `product-service` 的接口，验证它是否成功调用了 `user-service` 并返回了组合后的数据。



### **4.3 本章小结**



我们完成了从单体到微服务最关键的一步——动手拆分。我们创建了独立的微服务，并解决了它们之间最基本的通信问题。同时，我们也清楚地看到了拆分后暴露出的新问题：

- 服务地址硬编码，如果 `user-service` 部署了多个实例怎么办？
- 如何优雅地处理服务调用失败？
- 如果有几十个服务，配置如何管理？

这些问题，都将在我们的下一门课程 **《第三门课：微服务治理核心 —— Spring Cloud Alibaba 全家桶精讲》** 中得到完美的解答。

------



## **课程总结与展望**



在本课程中，我们走过了一段完整的旅程：

- **从零开始**，使用 Spring Boot 构建了一个真实的单体应用。
- **深入理论**，理解了微服务架构演进的必然性。
- **动手实践**，成功将单体应用重构为了微服务。

你现在不仅是一个熟练的 Spring Boot 开发者，更是一位对现代应用架构有深刻理解的准·架构师。

**下一站，准备好进入真正的分布式世界，学习如何使用 Spring Cloud Alibaba 来“治理”我们创建的这些微服务，让它们组成一个稳定、高效、可靠的强大系统。

本课程是整个系列的核心，它将解决我们在第二门课结尾时遇到的所有分布式系统问题，带领学员构建一个真正稳定、可靠、可管理的微服务集群。

------



# **第三门课：微服务治理核心 —— Spring Cloud Alibaba 全家桶精讲**





## **课程信息**



- **课程名称：** 微服务治理核心 —— Spring Cloud Alibaba 全家桶精讲



## **课程概述 (Course Overview)**



欢迎来到云原生微服务系列课程的“心脏”部分！在上一门课程中，我们成功地将单体应用拆分为了独立的微服务。但这仅仅是开始，我们立即面临了一系列棘手的分布式系统问题：服务地址如何管理？配置文件如何统一？服务之间级联失败怎么办？谁来充当系统的统一入口？

本课程将带您深入探索目前业界最主流的微服务解决方案——Spring Cloud Alibaba。我们将逐一击破这些难题，学习并实战其核心组件：使用 Nacos 作为注册中心和配置中心，使用 OpenFeign 结合 LoadBalancer 实现智能的负载均衡，使用 Sentinel 实现强大的服务容错与保护，最后使用 Spring Cloud Gateway 构建统一的 API 网关。学完本课程，您将具备构建和治理一个完整、健壮、生产级的微服务体系的能力。



### **学习目标 (Learning Objectives)**



学完本课程后，您将能够：

1. **使用 Nacos** 实现服务的自动注册与发现，解决服务地址硬编码问题。
2. **使用 Nacos** 作为配置中心，实现所有微服务配置的集中管理和动态刷新。
3. **掌握 OpenFeign** 与负载均衡的结合，实现优雅、可靠的服务间调用。
4. **使用 Sentinel** 为微服务提供流控、熔断、降级等全方位的保护，防止雪崩效应。
5. **构建 Spring Cloud Gateway** 服务，作为整个微服务集群的统一流量入口，并实现动态路由。



### **目标学员 (Target Audience)**



- 已完成第二门课程，并对微服务拆分有实践经验的开发者。
- 希望从传统 Spring Cloud Netflix 体系迁移或学习 Spring Cloud Alibaba 的 Java 工程师。
- 准备构建或正在维护微服务系统的后端架构师。



### **前置要求 (Prerequisites)**



- **必须**：完成 **《第二门课：从单体到微服务》**，并理解其结尾提出的分布式挑战。
- **必须**：拥有上一门课拆分出的 `user-service` 和 `product-service` 两个项目代码。
- **必须**：熟练使用 Docker 启动和管理容器（承接第一门课）。



### **环境准备 (Environment Setup)**



1. **IDE, JDK, Maven, API工具**：与上一门课保持一致。
2. **Nacos Server**：微服务的注册中心与配置中心。
3. **Sentinel Dashboard**：用于可视化配置和监控 Sentinel 规则。
4. **Docker & Docker Compose**：我们将使用 Docker 快速启动 Nacos 和 Sentinel。

------



## **第一章：服务注册与发现 - Nacos Discovery**





### **1.1 学习目标**



- 理解服务注册中心的必要性。

- 使用 Docker 启动 Nacos Server。

- 将微服务注册到 Nacos。

  *改造 OpenFeign，实现基于服务名的动态寻址和负载均衡。



### **1.2 理论讲解**



- **问题回顾**：在上一课中，我们在 OpenFeign 的 `@FeignClient` 注解里硬编码了 URL (`url = "http://localhost:8081"`)。
  - **缺点**：无法动态适应 IP 和端口的变化；无法支持服务的水平扩展（多实例）。
- **解决方案：服务注册中心 (Service Registry)**
  - **角色**：
    1. **服务提供者 (Provider)**：启动时，将自己的服务名、IP、端口等信息“注册”到注册中心。并定时发送“心跳”表明自己还活着。
    2. **服务消费者 (Consumer)**：调用服务时，不再直连硬编码地址，而是向注册中心询问：“谁能提供‘user-service’服务？”。
    3. **注册中心 (Registry)**：维护一份可用的服务实例列表，当收到消费者查询时，返回一个或多个提供者的地址。



### **1.3 动手实战：接入 Nacos Discovery**



1. **使用 Docker 启动 Nacos Server**

   - 在终端执行以下命令：

     Bash

     ```
     docker run --name nacos-standalone -e MODE=standalone -p 8848:8848 -p 9848:9848 -d nacos/nacos-server:2.2.3
     ```

     - `-e MODE=standalone`：以单机模式启动，用于测试。
     - `-p 8848:8848`：Nacos 控制台和 API 的端口。

   - 启动后，访问 `http://localhost:8848/nacos`，默认用户名/密码为 `nacos/nacos`。

2. **微服务接入 Nacos**

   - **目标**：将 `user-service` 和 `product-service` 注册到 Nacos。

   - **第一步：添加依赖**。在两个项目的 `pom.xml` 中都加入 Nacos Discovery 的起步依赖。

     - *注意：* Spring Cloud Alibaba 需要配合 Spring Cloud Hoxton/2020+ 等版本，需要先在 `pom.xml` 的 `<dependencyManagement>` 中引入 Spring Cloud Alibaba 的 BOM。

     

     ```xml
     <dependency>
         <groupId>com.alibaba.cloud</groupId>
         <artifactId>spring-cloud-alibaba-dependencies</artifactId>
         <version>2021.0.4.0</version> <type>pom</type>
         <scope>import</scope>
     </dependency>
     
     <dependency>
         <groupId>com.alibaba.cloud</groupId>
         <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
     </dependency>
     ```

   - **第二步：修改配置**。在两个项目的 `application.yml` 中添加 Nacos Server 地址。

     

     ```yaml
     spring:
       application:
         name: user-service # 必须为每个服务指定一个唯一的服务名
       cloud:
         nacos:
           server-addr: localhost:8848 # Nacos服务器地址
     ```

     > 将 `user-service` 的 `name` 改为 `user-service`，`product-service` 的 `name` 改为 `product-service`。

   - **第三步：启用服务发现**。在两个项目的主启动类上添加 `@EnableDiscoveryClient` 注解。

3. **验证注册结果**

   - 依次启动 `user-service` 和 `product-service`。
   - 回到 Nacos 控制台，在 "服务管理" -> "服务列表" 中，你应该能看到 `user-service` 和 `product-service` 已经注册成功，并且实例数量为 1。

4. **改造 OpenFeign (关键一步！)**

   - 打开 `product-service` 中的 `UserClient` 接口。

   - **修改 `@FeignClient` 注解：**

     

     ```Java
     // 旧代码: @FeignClient(name = "userservice", url = "http://localhost:8081")
     // 新代码:
     @FeignClient("user-service") // 直接使用在Nacos中注册的服务名
     public interface UserClient {
         // ... 方法不变
     }
     ```

   - **重新启动 `product-service`** 并用 Postman 调用之前的接口。

   - **见证奇迹：** 调用依然成功！但这次，Feign 不再依赖硬编码的 URL，而是通过 Nacos 拿到了 `user-service` 的地址。

   - **水平扩展测试**：

     - 使用不同的端口号（例如 `server.port=8082`）再启动一个 `user-service` 实例。
     - 刷新 Nacos 控制台，会看到 `user-service` 的实例数变为 2。
     - 连续多次调用 `product-service` 的接口，观察两个 `user-service` 实例的控制台日志，你会发现请求被**轮流**分发到了两个实例上。这就是**客户端负载均衡**！



### **1.4 本章小结**



我们解决了微服务架构的第一个核心问题——服务寻址。通过引入 Nacos，我们实现了服务的动态注册与发现，并让 OpenFeign 具备了自动化的客户端负载均衡能力，为构建高可用的系统迈出了关键一步。

------



## **第二章：统一配置管理 - Nacos Config**





### **2.1 学习目标**



- 理解集中配置管理的必要性。
- 将微服务的本地配置迁移到 Nacos。
- 实现配置的动态刷新。



### **2.2 理论讲解**



- **问题**：目前，每个微服务的配置（如数据库地址、Redis地址）都写在各自的 `application.yml` 文件中。
  - **痛点**：当服务数量增多，或多个服务共享同一份配置时，修改配置需要逐个服务更改并重新部署，效率低下且容易出错。
- **解决方案：配置中心 (Configuration Center)**
  - 将所有配置集中存储在一个地方（Nacos）。
  - 各个微服务在启动时，从配置中心拉取自己的配置。
  - **核心优势**：可以实现配置的**动态刷新**，即修改配置后，应用无需重启即可生效。



### **2.3 动手实战：接入 Nacos Config**



1. **添加依赖**

   - 在 `user-service` 和 `product-service` 的 `pom.xml` 中，添加 Nacos Config 的起步依赖：

     

     ```xml
     <dependency>
         <groupId>com.alibaba.cloud</groupId>
         <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
     </dependency>
     ```

2. **创建 `bootstrap.yml`**

   - Nacos Config 的配置需要优先于 `application.yml` 加载，因此我们需要在 `src/main/resources` 目录下创建一个 `bootstrap.yml` 文件。

   - 在两个项目中都创建该文件，并写入以下内容：

     

     ```yaml
     spring:
       application:
         name: user-service # 同样要指定服务名
       cloud:
         nacos:
           server-addr: localhost:8848
           config:
             file-extension: yaml # 指定配置文件格式为 yaml
     ```

3. **在 Nacos UI 中创建配置**

   - 进入 Nacos 控制台 -> "配置管理" -> "配置列表"。

   - 点击右侧的 "+" 号，新建配置。

   - **Data ID**：命名规则通常是 `{spring.application.name}-{spring.profiles.active}.{file-extension}`。例如，`user-service-dev.yaml`。

   - **Group**：保持 `DEFAULT_GROUP` 即可。

   - **配置格式**：选择 `YAML`。

   - **配置内容**：将 `user-service` 本地 `application.yml` 中关于数据库、MyBatis 等业务配置**剪切**并**粘贴**到这里。

     

     ```yaml
     # Nacos中 user-service-dev.yaml 的内容
     spring:
       datasource:
         url: jdbc:mysql://localhost:3306/user_db?useSSL=false&serverTimezone=UTC
         username: root
         password: your_password
     
     mybatis-plus:
       mapper-locations: classpath:/mapper/*.xml
     
     # 我们可以加一个自定义配置用于测试动态刷新
     user:
       greeting: "Hello from Nacos!"
     ```

   - 点击 "发布"。用同样的方式为 `product-service` 创建配置。

4. **动态刷新实战**

   - 在 `user-service` 的 `HelloController` (或任意 Controller) 中，注入这个自定义配置：

     

     ```java
     import org.springframework.beans.factory.annotation.Value;
     import org.springframework.cloud.context.config.annotation.RefreshScope;
     
     @RestController
     @RefreshScope // 关键注解！
     public class HelloController {
     
         @Value("${user.greeting}")
         private String greeting;
     
         @GetMapping("/greeting")
         public String getGreeting() {
             return greeting;
         }
         // ... 其他代码
     }
     ```

     - `@RefreshScope` 注解使得该 Bean 具备了动态刷新配置的能力。

5. **验证**

   - 删除 `user-service` 本地 `application.yml` 中的业务配置，只保留 `server.port` 等基础信息。
   - 启动 `user-service`。应用应该能正常连接数据库，证明它成功从 Nacos 拉取了配置。
   - 访问 `http://localhost:8081/greeting`，会返回 "Hello from Nacos!"。
   - 回到 Nacos UI，修改 `user-service-dev.yaml` 中的 `user.greeting` 为 "Hi, Config has been updated!"，然后发布。
   - **无需重启应用**，再次访问 `http://localhost:8081/greeting`，你会发现返回内容已经变成了新的值！



### **2.4 本章小结**



我们通过 Nacos Config 实现了配置的“动静分离”和集中化管理，并体验了其“动态刷新”的强大特性，极大地提升了微服务架构的运维效率和灵活性。

------



## **第三章：服务容错与保护 - Sentinel**





### **3.1 学习目标**



- 理解分布式系统中的雪崩效应。
- 使用 Docker 启动 Sentinel Dashboard。
- 为微服务接入 Sentinel。
- 通过 Dashboard 配置流控和熔断降级规则。
- 为 OpenFeign 调用添加 fallback 降级逻辑。



### **3.2 理论讲解**



- **雪崩效应 (Cascading Failure)**
  - 在微服务架构中，一个服务（如 `user-service`）的延迟或不可用，会导致调用方（`product-service`）的线程阻塞、资源耗尽，最终导致调用方也变得不可用。这种故障会像雪崩一样在服务调用链中传导，最终导致整个系统瘫痪。
- **Sentinel 的三大核心功能**
  1. **流量控制 (Flow Control)**：通过 QPS（每秒请求数）或并发线程数来限制对资源的访问，防止服务被瞬时大流量冲垮。
  2. **熔断降级 (Circuit Breaking & Degrade)**：当一个不稳定的资源（如响应慢、频繁出错的下游服务）达到某个阈值时，Sentinel 会对其进行“熔断”，在接下来的时间窗口内，对该资源的调用会直接失败并快速返回，而不是长时间等待。这避免了故障的蔓延。
  3. **系统负载保护 (System Adaptive Protection)**：根据当前系统的负载情况（如 Load Average, CPU Usage），自动调整流量，保护系统不被压垮。



### **3.3 动手实战：接入 Sentinel**



1. **使用 Docker 启动 Sentinel Dashboard**

   Bash

   ```
   docker run --name sentinel-dashboard -p 8080:8080 -d bladex/sentinel-dashboard
   ```

   - 访问 `http://localhost:8080`，默认用户名/密码为 `sentinel/sentinel`。

2. **微服务接入 Sentinel**

   - **目标**：为 `product-service` 提供保护，因为它依赖 `user-service`。

   - **第一步：添加依赖**。在 `product-service` 的 `pom.xml` 中加入：

     XML

     ```
     <dependency>
         <groupId>com.alibaba.cloud</groupId>
         <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>
     </dependency>
     ```

   - **第二步：修改配置**。在 `product-service` 的 `application.yml` 中添加 Sentinel Dashboard 的地址。

     YAML

     ```
     spring:
       cloud:
         sentinel:
           transport:
             dashboard: localhost:8080
     ```

   - **第三步：启动 `product-service`**，并用 Postman 访问其任意接口一次。然后刷新 Sentinel Dashboard，你会在左侧看到 `product-service` 已经出现。

3. **配置流控规则**

   - 在 Sentinel Dashboard 中，找到 `product-service`，点击 "簇点链路"。这里会列出所有可以被保护的资源（通常是 Controller 的接口方法）。
   - 找到你要保护的接口，例如 `/products/{id}/with-user`，点击右侧的 "流控" 按钮。
   - **设置 QPS 阈值为 1**，点击 "新增"。
   - 使用 Postman 或 JMeter 快速连续访问该接口，你会发现只有第一次成功，后续的请求会很快收到一个错误响应（"Blocked by Sentinel (flow limiting)"）。

4. **为 OpenFeign 配置熔断降级与 Fallback**

   - **第一步：开启 Feign 对 Sentinel 的支持**。在 `product-service` 的 `application.yml` 中：

     YAML

     ```
     feign:
       sentinel:
         enabled: true
     ```

   - **第二步：创建 Fallback 处理类**。这个类需要实现你的 Feign 客户端接口 (`UserClient`)，并提供服务调用失败后的降级逻辑。

     Java

     ```
     package com.example.productservice.client;
     
     import org.springframework.stereotype.Component;
     
     @Component
     public class UserClientFallback implements UserClient {
         @Override
         public UserDTO findById(Long id) {
             // 这是服务调用失败后的降级逻辑
             UserDTO fallbackUser = new UserDTO();
             fallbackUser.setId(id);
             fallbackUser.setUsername("默认用户 (服务降级)");
             return fallbackUser;
         }
     }
     ```

   - **第三步：在 `@FeignClient` 注解中指定 Fallback 类**。

     Java

     ```
     @FeignClient(value = "user-service", fallback = UserClientFallback.class)
     public interface UserClient {
         // ...
     }
     ```

   - **第四步：测试**。

     - 启动 `product-service`。
     - **手动停止 `user-service`**，模拟下游服务故障。
     - 此时再调用 `product-service` 的接口，它不会再报错或长时间等待，而是会立即返回你在 `UserClientFallback` 中定义的“默认用户”。



### **3.4 本章小结**



我们为系统引入了“保险丝”——Sentinel。通过流量控制，我们保护了服务免受流量冲击；通过熔断降级，我们避免了级联失败，大大提升了整个微服务体系的稳定性和韧性。

------



## **第四章：统一 API 入口 - Spring Cloud Gateway**





### **4.1 学习目标**



- 理解 API 网关在微服务架构中的作用。
- 创建一个独立的 Spring Cloud Gateway 服务。
- 配置动态路由，将请求转发到后端的微服务。



### **4.2 理论讲解**



- **问题**：
  - 前端应用（Web/App）需要知道所有微服务的地址，增加了客户端的复杂性。
  - 认证、授权、日志、限流等通用逻辑需要在每个微服务中重复实现。
  - CORS 跨域问题处理起来很麻烦。
- **API 网关 (API Gateway)**
  - 它是整个微服务系统的**唯一入口**。所有外部请求都先经过网关，再由网关根据请求的 URL 路径等信息，将其**路由**到后端的具体微服务。
  - **核心职责**：
    1. **请求路由 (Routing)**：核心功能。
    2. **统一鉴权 (Authentication)**：可以在网关层统一做掉 token 校验。
    3. **日志记录 (Logging)**：记录所有请求的日志。
    4. **限流熔断 (Rate Limiting)**：对外部流量进行第一层保护。
    5. **协议转换**：例如将外部的 HTTP 请求转换为内部的 RPC 调用。



### **4.3 动手实战：构建 Gateway 服务**



1. **创建新的 Spring Boot 项目**

   - 使用 Spring Initializr 创建一个名为 `gateway-service` 的项目。
   - **添加依赖**：
     - `Spring Cloud Gateway`
     - `Nacos Discovery Client` (因为网关也需要从 Nacos 发现后端服务)

2. **配置 `application.yml`**

   YAML

   ```
   server:
     port: 80 # 网关通常监听 80 端口
   
   spring:
     application:
       name: gateway-service
     cloud:
       nacos:
         server-addr: localhost:8848
       gateway:
         # 开启基于服务发现的路由功能
         discovery:
           locator:
             enabled: true
             lower-case-service-id: true # 将服务名转为小写路径
   
         # 自定义路由规则 (更灵活，推荐)
         routes:
           # 用户服务的路由规则
           - id: user_route
             uri: lb://user-service # lb:// 表示从Nacos加载并负载均衡
             predicates:
               - Path=/user-api/** # 断言：凡是/user-api/开头的请求
             filters:
               - StripPrefix=1 # 过滤器：转发时去掉路径的第一部分(/user-api)
   
           # 商品服务的路由规则
           - id: product_route
             uri: lb://product-service
             predicates:
               - Path=/product-api/**
             filters:
               - StripPrefix=1
   ```

3. **启动并测试**

   - 依次启动 Nacos, `user-service`, `product-service`, `gateway-service`。
   - **测试用户服务**：
     - 原地址：`http://localhost:8081/users/1`
     - **网关地址**：`http://localhost/user-api/users/1`
   - **测试商品服务**：
     - 原地址：`http://localhost:8082/products/1`
     - **网关地址**：`http://localhost/product-api/products/1`
   - 你会发现，所有请求都可以通过网关的 80 端口进行访问，网关根据路径自动将请求转发给了正确的后端服务。



### **4.4 本章小结**



我们成功构建了系统的“守门人”——API 网关。它统一了系统入口，简化了客户端的调用，并为实现认证、限流等横切关注点提供了一个完美的平台。

------



## **课程总结与展望**



在本课程中，我们使用 Spring Cloud Alibaba 全家桶，为上一课中拆分出的“裸奔”的微服务穿上了一套坚实的“铠甲”：

- **Nacos** 解决了服务的注册发现和配置管理。
- **Sentinel** 解决了服务的容错和保护。
- **Gateway** 解决了服务的统一入口和路由。

至此，我们已经拥有了一个功能完备、治理完善的微服务技术栈。你已经具备了设计和开发中大型微服务系统的核心能力。

下一步的挑战是什么？

我们开发和治理好了微服务，但如何将它们高效、可靠、自动化地部署到生产环境的服务器集群中呢？这就是我们下一门课程 《第四门课：生产级部署与编排 —— Kubernetes (K8s) 实战》 将要解决的核心问题。我们将学习如何将今天构建的整个微服务体系打包成 Docker 镜像，并部署到 K8s 集群中，实现真正的云原生交付。

**感谢大家的学习，课程结束！**



好的，我们无缝衔接，进入云原生之旅中至关重要的一环——Kubernetes。

这是《第四门课：生产级部署与编排 —— Kubernetes (K8s) 实战》的完整教学文档。本课程将带领学员从 Docker Compose 的单机编排，跃升至真正的生产级、分布式集群编排，是成为一名合格云原生工程师的必经之路。

------



# **第四门课：生产级部署与编排 —— Kubernetes (K8s) 实战**





## **课程信息**



- **课程名称：** 生产级部署与编排 —— Kubernetes (K8s) 实战



## **课程概述 (Course Overview)**



欢迎来到云原生微服务系列课程的第四站，也是通往自动化运维和大规模部署的“天梯”！在前三门课程中，我们已经掌握了如何开发、治理一个完整的微服务体系。但是，当我们需要将几十甚至上百个服务实例部署到生产环境的服务器集群时，手动的 `docker run` 或单机的 `docker-compose` 显然已力不从心。

本课程将带您深入学习目前容器编排领域的事实标准——Kubernetes (简称 K8s)。我们将从 K8s 的核心理念和架构讲起，手把手带您搭建本地 K8s 集群。您将学习到如何通过声明式的 YAML 文件，精确地定义和部署应用，并掌握 Pod, Deployment, Service, Ingress 等核心资源对象的用法。本课程的最终目标，是将我们在上一课构建的整套 Spring Cloud Alibaba 微服务体系，完整、可靠地部署到 Kubernetes 集群中，实现服务的自动伸缩、故障自愈和滚动更新，真正迈入云原生时代。



### **学习目标 (Learning Objectives)**-



学完本课程后，您将能够：

1. **阐述** Kubernetes 的核心架构和工作原理。
2. **熟练使用** `kubectl` 命令行工具管理 K8s 集群。
3. **独立编写** YAML 配置文件来部署、管理和暴露应用程序。
4. **掌握** K8s 中无状态应用 (Deployment) 和有状态应用 (StatefulSet) 的部署模式。
5. **理解** K8s 的服务发现、负载均衡、配置管理和持久化存储机制。
6. **具备** 将一个复杂的多服务微服务应用迁移和部署到 Kubernetes 集群的综合实战能力。



### **目标学员 (Target Audience)**



- 已完成前三门课程，希望学习生产级部署方案的开发者。
- 希望从传统运维转型为 DevOps 或 SRE 的工程师。
- 对云原生技术栈和自动化运维充满热情的IT从业者。



### **前置要求 (Prerequisites)**



- **必须**：完成 **《第一门课：Docker 容器化技术详解》**，对 Docker 镜像和容器有深入理解。
- **必须**：拥有前几门课程构建的微服务项目的 Docker 镜像（或者能够随时构建）。
- **推荐**：了解基本的网络概念（IP, 端口, DNS, 负载均衡）。
- **推荐**：对 YAML 语法有基本了解。



### **环境准备 (Environment Setup)**



1. **Docker Desktop (强烈推荐)**：对于 Windows 和 macOS 用户，Docker Desktop 自带了单节点的 Kubernetes 集群，是学习和测试最方便的选择。请确保在 `Settings -> Kubernetes` 中勾选 "Enable Kubernetes"。
2. **Minikube**：一个跨平台的本地 K8s 集群搭建工具。如果无法使用 Docker Desktop，Minikube 是最佳备选。
3. **kubectl**：Kubernetes 的命令行客户端。Docker Desktop 会自动安装。如果单独安装，请参考 [官方文档](https://kubernetes.io/docs/tasks/tools/install-kubectl/)。
4. **代码编辑器**：VS Code 并安装 `Kubernetes` 和 `YAML` 插件，可以提供语法高亮和智能提示。

------



## **第一章：初识 Kubernetes 与环境搭建**





### **1.1 学习目标**



- 理解 Docker Compose 的局限性和 K8s 的价值。
- 了解 K8s 的 Master-Node 核心架构。
- 成功启动一个本地 K8s 集群。
- 掌握 `kubectl` 的基本配置和常用命令。



### **1.2 理论讲解**



- **从 Docker Compose 到 Kubernetes 的飞跃**
  - **Docker Compose**：是 **单机** 编排工具。它能在**一台**服务器上帮你管理多个容器的生命周期。
  - **Kubernetes**：是 **集群级** 编排系统。它能在**多台**服务器（物理机或虚拟机）组成的集群上，作为一个整体来调度和管理成千上万的容器。
- **K8s 的核心能力**
  - **服务发现与负载均衡**：自动为容器分配 IP 和 DNS，并在多个副本之间分发流量。
  - **自动装箱**：根据容器所需的资源（CPU, 内存）自动将其调度到最合适的节点上运行。
  - **故障自愈 (Self-healing)**：当容器或节点挂掉时，K8s 会自动替换或重新调度，确保服务持续可用。
  - **滚动更新与回滚**：可以零停机地发布新版本，如果发现问题，也能一键回滚到旧版本。
  - **密钥与配置管理**：统一管理敏感信息（如密码）和应用配置，与镜像解耦。
- **K8s 核心架构**
  - **Master 节点 (控制平面 Control Plane)**：集群的大脑，负责管理和决策。
    - `kube-apiserver`: 整个集群的统一入口，提供 REST API。
    - `etcd`: 一个高可用的键值数据库，存储了集群的所有状态。
    - `kube-scheduler`: 负责决定将新的 Pod 调度到哪个 Node 上。
    - `kube-controller-manager`: 运行各种控制器，维持集群的状态（如副本数量）。
  - **Node 节点 (工作节点)**：真正运行容器的地方。
    - `kubelet`: 与 Master 通信，管理本节点上的 Pod。
    - `kube-proxy`: 负责节点上的网络代理和负载均衡。
    - `Container Runtime`: 容器运行时，如 Docker 或 containerd。



### **1.3 动手实战：启动你的第一个 K8s 集群**



1. **启用 Docker Desktop 中的 Kubernetes**

   - 打开 Docker Desktop -> Settings (设置) -> Kubernetes。
   - 勾选 "Enable Kubernetes"，点击 "Apply & Restart"。
   - 等待几分钟，直到左下角的 K8s 图标变绿。

2. **配置并验证 `kubectl`**

   - `kubectl` 的配置文件位于 `~/.kube/config`。Docker Desktop 会自动为你配置好。

   - 打开终端，执行以下命令验证 `kubectl` 是否可以连接到集群：

     Bash

     ```
     # 查看客户端和服务器版本
     kubectl version
     
     # 查看集群信息
     kubectl cluster-info
     
     # 查看集群中的所有节点 (Node)
     kubectl get nodes
     ```

     *预期输出：* 你应该能看到一个名为 `docker-desktop` 的节点，其状态为 `Ready`。

3. **`kubectl` 命令自动补全 (强烈推荐)**

   - 这将极大提升你的工作效率。

   - **Bash:**

     Bash

     ```
     source <(kubectl completion bash)
     echo "source <(kubectl completion bash)" >> ~/.bashrc
     ```

   - **Zsh:**

     Bash

     ```
     source <(kubectl completion zsh)
     echo "source <(kubectl completion zsh)" >> ~/.zshrc
     ```



### **1.4 本章小结**



我们理解了 K8s 作为集群编排系统的核心价值，并掌握了其 Master-Node 架构。最重要的是，我们成功地在本地启动了一个功能完备的 K8s 集群，并配置好了 `kubectl` 工具，为后续的所有实战铺平了道路。

------



## **第二章：K8s 核心资源对象 (上)**





### **2.1 学习目标**



- 理解 K8s 声明式 API 的思想。
- 掌握最小部署单元 Pod。
- 使用 Label 和 Selector 来组织和选择资源。
- 通过 Deployment 实现应用的部署和扩缩容。
- 通过 Service (ClusterIP) 实现集群内部的服务发现。



### **2.2 理论讲解**



- **声明式 vs 命令式**
  - **命令式** (如 `docker run ...`)：你告诉系统“做什么”（Do this, then do that）。
  - **声明式** (K8s YAML)：你告诉系统你“想要什么状态”（I want this state），系统会自己想办法达到这个状态。这是 K8s 的核心哲学。
- **核心资源对象**
  - **Pod**: K8s 中**最小**的部署和调度单元。一个 Pod 包含一个或多个紧密相关的容器，它们共享网络和存储。通常情况下，一个 Pod 只运行一个主容器。
  - **Label (标签)**: 附加到资源上的键值对，用于标识和组织。例如 `app: nginx`, `env: production`。
  - **Selector (选择器)**: 用于根据 Label 筛选出一组资源。
  - **Deployment**: 一个更高级别的控制器，用于管理 Pod 的生命周期。它能确保指定数量的 Pod 副本（Replica）一直处于运行状态，并支持滚动更新和回滚。**我们通常不直接创建 Pod，而是通过 Deployment 来管理。**
  - **Service (服务)**: 为一组 Pod 提供一个**稳定**的访问入口。Service 有一个固定的 IP 地址（Cluster IP）和 DNS 名称。即使后端的 Pod 因为故障或更新而发生 IP 变化，Service 的地址始终不变。



### **2.3 动手实战：部署第一个 Nginx 应用**



1. **创建 YAML 文件**

   - 创建一个 `nginx-deployment.yaml` 文件，输入以下内容：

     YAML

     ```
     # API 版本
     apiVersion: apps/v1
     # 资源类型
     kind: Deployment
     # 元数据
     metadata:
       name: nginx-deployment
     # 规格
     spec:
       # 期望的 Pod 副本数量
       replicas: 2
       # 选择器，用于关联要管理的 Pod
       selector:
         matchLabels:
           app: nginx
       # Pod 的模板，定义了要创建的 Pod 的具体内容
       template:
         metadata:
           labels:
             app: nginx
         spec:
           containers:
           - name: nginx-container
             image: nginx:1.21
             ports:
             - containerPort: 80
     ```

2. **应用 YAML 文件**

   - 在终端中执行：

     Bash

     ```
     kubectl apply -f nginx-deployment.yaml
     ```

3. **查看资源状态**

   - **查看 Deployment**:

     Bash

     ```
     kubectl get deployments
     # 或缩写 kubectl get deploy
     ```

   - **查看 Pod**:

     Bash

     ```
     kubectl get pods
     # 或缩写 kubectl get po
     # 使用 -o wide 可以看到更多信息，如 Pod IP 和所在节点
     kubectl get po -o wide
     ```

     *预期结果：* 你会看到两个名为 `nginx-deployment-...` 的 Pod 正在运行。

   - **扩容/缩容**:

     Bash

     ```
     # 将副本数扩展到 3 个
     kubectl scale deployment nginx-deployment --replicas=3
     kubectl get po # 验证
     ```

4. **创建 Service 暴露应用**

   - 目前，这些 Pod 只能在集群内部通过各自的 IP 访问，且 IP 会变化。我们需要一个 Service。

   - 创建一个 `nginx-service.yaml` 文件：

     YAML

     ```
     apiVersion: v1
     kind: Service
     metadata:
       name: nginx-service
     spec:
       # Service 类型，ClusterIP 是默认类型，只在集群内部可见
       type: ClusterIP
       # 选择器，将流量转发到带有 app=nginx 标签的 Pod
       selector:
         app: nginx
       ports:
         # Service 监听的端口
         - port: 80
           # Pod 暴露的端口
           targetPort: 80
     ```

   - 应用它：

     Bash

     ```
     kubectl apply -f nginx-service.yaml
     ```

   - 查看 Service：

     Bash

     ```
     kubectl get services
     # 或缩写 kubectl get svc
     ```

     *预期结果：* 你会看到 `nginx-service` 获得了一个 Cluster IP。

5. **在集群内部验证访问**

   - 我们可以临时创建一个 Pod 来充当客户端：

     Bash

     ```
     kubectl run curl-client --image=curlimages/curl -it --rm -- /bin/sh
     ```

   - 在进入这个临时 Pod 的 shell 后，使用 Service 的 DNS 名称访问 Nginx：

     Bash

     ```
     # 在 curl-client Pod 的 shell 中执行
     curl http://nginx-service
     ```

     *预期结果：* 你会看到 Nginx 的欢迎页面 HTML。这证明了 Service 成功地将请求路由到了后端的 Pod。



### **2.4 本章小结**



我们掌握了 K8s 中最核心的几个资源对象，并成功部署了一个无状态应用。我们理解了通过 Deployment 管理应用生命周期，通过 Service 实现内部服务发现的黄金搭档模式。

------



## **第三章：K8s 核心资源对象 (下)**





### **3.1 学习目标**



- 使用 `NodePort` 和 `LoadBalancer` 类型的 Service 从外部访问应用。
- 使用 `ConfigMap` 和 `Secret` 管理应用的配置和敏感数据。
- 使用 `Ingress` 实现基于域名的七层路由。



### **3.2 动手实战：暴露并配置应用**



1. **通过 `NodePort` 暴露服务**

   - `NodePort` 会在集群的**每个 Node** 上都开放一个**相同**的静态端口，外部流量可以通过 `[Node_IP]:[NodePort]` 访问到 Service。

   - 修改 `nginx-service.yaml`：

     YAML

     ```
     ...
     spec:
       type: NodePort # 修改类型
       selector:
         app: nginx
       ports:
         - port: 80
           targetPort: 80
           nodePort: 30007 # 可以指定一个端口，范围 30000-32767，不指定会自动分配
     ```

   - 重新应用 `kubectl apply -f nginx-service.yaml`。

   - 现在，你可以通过 `http://localhost:30007` 访问到 Nginx 了（因为 `docker-desktop` 节点的 IP 就是 `localhost`）。

2. **使用 `ConfigMap` 管理配置**

   - `ConfigMap` 用于存储非敏感的配置数据。

   - 创建一个 `nginx-configmap.yaml`：

     YAML

     ```
     apiVersion: v1
     kind: ConfigMap
     metadata:
       name: nginx-index-html-configmap
     data:
       # key: index.html
       index.html: |
         <!DOCTYPE html>
         <html>
         <head>
         <title>Welcome from ConfigMap!</title>
         </head>
         <body>
         <h1>This page is managed by a Kubernetes ConfigMap!</h1>
         </body>
         </html>
     ```

   - 应用它 `kubectl apply -f nginx-configmap.yaml`。

   - 修改 `nginx-deployment.yaml`，将 ConfigMap 挂载为文件：

     YAML

     ```
     ...
     spec:
       containers:
       - name: nginx-container
         image: nginx:1.21
         ports:
         - containerPort: 80
         # 添加 volumeMounts
         volumeMounts:
         - name: nginx-index-volume
           mountPath: /usr/share/nginx/html # 挂载到 Nginx 的默认站点目录
       # 添加 volumes
       volumes:
       - name: nginx-index-volume
         configMap:
           name: nginx-index-html-configmap
     ```

   - 重新应用 `kubectl apply -f nginx-deployment.yaml`。K8s 会进行滚动更新。

   - 再次访问 `http://localhost:30007`，你会看到页面内容已经变成了我们 ConfigMap 中定义的内容。

3. **使用 `Ingress` 实现域名访问 (最重要)**

   - `NodePort` 和 `LoadBalancer` 都是四层代理，而 `Ingress` 是七层（HTTP/HTTPS）代理，可以根据域名和路径进行路由，是暴露 Web 应用的**推荐方式**。

   - **第一步：安装 Ingress Controller**。Ingress 资源本身只是规则，需要一个 Controller 来实现这些规则。Docker Desktop 自带了 Nginx Ingress Controller，我们只需启用它。对于其他集群，通常需要手动安装。

   - **第二步：创建 `ingress.yaml`**：

     YAML

     ```
     apiVersion: networking.k8s.io/v1
     kind: Ingress
     metadata:
       name: nginx-ingress
     spec:
       rules:
       - host: my-nginx.local # 我们将要访问的域名
         http:
           paths:
           - path: /
             pathType: Prefix
             backend:
               service:
                 name: nginx-service # 将流量转发到这个 Service
                 port:
                   number: 80
     ```

   - **第三步：配置本地 DNS**。编辑你的 `hosts` 文件，添加一条记录：

     - Windows: `C:\Windows\System32\drivers\etc\hosts`
     - macOS/Linux: `/etc/hosts`
     - 添加内容：`127.0.0.1 my-nginx.local`

   - **第四步：应用 Ingress** `kubectl apply -f ingress.yaml`。

   - 现在，你可以通过 `http://my-nginx.local` 访问 Nginx 了！



### **3.3 本章小结**



我们掌握了将应用暴露到集群外部的多种方式，并学会了使用 `ConfigMap` 和 `Ingress` 这两个在生产环境中必不可少的资源。我们现在已经具备部署一个完整 Web 应用的能力。

------



## **第四章：高级特性与应用管理**





### **4.1 学习目标**



- 配置健康检查探针（Liveness, Readiness）以提升应用可靠性。
- 为容器设置资源请求和限制（Requests & Limits）。
- 使用 `PersistentVolume` 和 `PersistentVolumeClaim` 为有状态应用提供持久化存储。



### **4.2 理论讲解**



- **健康检查探针 (Probes)**
  - **Liveness Probe (存活探针)**: K8s 用它来判断容器是否**还活着**。如果探测失败，`kubelet` 会杀死并重启这个容器。用于检测死锁等问题。
  - **Readiness Probe (就绪探针)**: K8s 用它来判断容器是否**准备好接收流量**。如果探测失败，K8s 会将这个 Pod 从 Service 的后端端点中移除，流量不再转发给它。用于处理应用启动慢、需要预热等场景。
- **资源管理 (Requests & Limits)**
  - **Requests (请求)**: 容器**保证**可以获得的最小资源量。K8s `scheduler` 会根据 `requests` 来决定将 Pod 调度到哪个节点。
  - **Limits (限制)**: 容器**最多**可以使用的资源量。如果超过，可能会被杀死（内存）或限制（CPU）。
- **持久化存储**
  - **PersistentVolume (PV)**: 集群中的一块存储资源，由管理员创建和管理。
  - **PersistentVolumeClaim (PVC)**: 用户（应用）对存储资源的**申请**。用户不需要关心存储的具体实现，只需要申请所需的大小和访问模式。K8s 会将合适的 PV 绑定到 PVC 上。



### **4.3 动手实战：部署有状态应用 MySQL**



1. **创建 `mysql-pvc.yaml`**

   YAML

   ```
   apiVersion: v1
   kind: PersistentVolumeClaim
   metadata:
     name: mysql-pvc
   spec:
     accessModes:
       - ReadWriteOnce # 只能被单个节点读写挂载
     resources:
       requests:
         storage: 1Gi # 申请 1G 的存储空间
   ```

2. **创建 `mysql-secret.yaml`**

   YAML

   ```
   apiVersion: v1
   kind: Secret
   metadata:
     name: mysql-secret
   type: Opaque
   stringData:
     # 使用 stringData 可以不用 base64 编码
     ROOT_PASSWORD: "your_strong_password"
   ```

3. **创建 `mysql-deployment.yaml`**

   YAML

   ```
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: mysql
   spec:
     replicas: 1
     selector:
       matchLabels:
         app: mysql
     template:
       metadata:
         labels:
           app: mysql
       spec:
         containers:
         - name: mysql
           image: mysql:5.7
           ports:
           - containerPort: 3306
           env:
           - name: MYSQL_ROOT_PASSWORD
             valueFrom:
               secretKeyRef:
                 name: mysql-secret
                 key: ROOT_PASSWORD
           volumeMounts:
           - name: mysql-persistent-storage
             mountPath: /var/lib/mysql
         volumes:
         - name: mysql-persistent-storage
           persistentVolumeClaim:
             claimName: mysql-pvc
   ```

4. **创建 `mysql-service.yaml`** (用于集群内部访问)

   YAML

   ```
   apiVersion: v1
   kind: Service
   metadata:
     name: mysql-service
   spec:
     ports:
     - port: 3306
     selector:
       app: mysql
   ```

5. **依次应用所有 YAML 文件**

   - `kubectl apply -f mysql-secret.yaml`
   - `kubectl apply -f mysql-pvc.yaml`
   - `kubectl apply -f mysql-deployment.yaml`
   - `kubectl apply -f mysql-service.yaml`
   - K8s 会自动创建 PV (在 Docker Desktop 中)，并将其与 PVC 绑定，然后启动 MySQL Pod 并挂载该存储。



### **4.4 本章小结**



我们学习了如何通过健康检查和资源管理来提升应用的稳定性和资源利用率，并通过 PV/PVC 模型成功部署了一个有状态的数据库应用，为部署完整的微服务体系扫清了最后的障碍。

------



## **第五章：将微服务项目部署到 K8s**





### **5.1 学习目标**



- 为课程项目的每个微服务编写 K8s 部署 YAML。
- 在 K8s 中部署 Nacos Server。
- 配置水平自动伸缩 (HPA)。



### **5.2 终极实战：云原生部署**



**第一步：将所有微服务打包成 Docker 镜像**

- 确保你的 `user-service`, `product-service`, `gateway-service` 都有高效的 `Dockerfile` (推荐使用多阶段构建)。

- 构建镜像并推送到镜像仓库（如 Docker Hub, Harbor, 阿里云ACR）。**K8s 默认不会使用本地镜像**，必须从仓库拉取。

  Bash

  ```
  docker build -t your-repo/user-service:1.0 .
  docker push your-repo/user-service:1.0
  # ... 对所有服务执行此操作
  ```

**第二步：在 K8s 中部署 Nacos**

- 对于生产环境，推荐使用 Nacos 的 K8s Operator 或 Helm Chart。为简化学习，我们先用 Deployment + StatefulSet 的方式。
- (此处提供简化的 Nacos 单机部署 YAML，包含 Deployment 和 Service)

**第三步：为 `user-service` 编写部署文件 `user-service.yaml`**

YAML

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
    spec:
      containers:
      - name: user-service
        image: your-repo/user-service:1.0 # 替换为你的镜像
        ports:
        - containerPort: 8081
        env:
        - name: NACOS_SERVER_ADDR
          value: "nacos-service.default.svc.cluster.local:8848" # 使用 K8s 内部 DNS
        - name: DATABASE_HOST
          value: "mysql-service" # 同上
---
apiVersion: v1
kind: Service
metadata:
  name: user-service
spec:
  selector:
    app: user-service
  ports:
  - port: 8081
    targetPort: 8081
```

**第四步：为 `product-service` 和 `gateway-service` 编写类似的部署文件。**

**第五步：为 Gateway Service 创建 Ingress**

- 创建一个 `gateway-ingress.yaml`，将 `my-app.local` 域名路由到 `gateway-service`。

**第六步：部署所有服务**

- 依次 `kubectl apply -f` 所有 YAML 文件。
- 使用 `kubectl get pods`, `kubectl get svc`, `kubectl logs` 等命令检查所有服务是否正常启动、注册到 Nacos，并能互相通信。

**第七步：配置 HPA (Horizontal Pod Autoscaler)**

- HPA 可以根据 CPU 或内存使用率自动增减 Pod 的副本数。

- **前提**：必须为容器设置 `requests` 资源。

- 为 `user-service` 创建一个 HPA：

  Bash

  ```
  # 当 CPU 使用率超过 50% 时，自动扩容，最多 10 个副本，最少 2 个
  kubectl autoscale deployment user-service-deployment --cpu-percent=50 --min=2 --max=10
  ```

- 可以使用压力测试工具来观察 HPA 的效果。



### **5.3 本章小结**



我们完成了本课程的终极目标！成功地将一个复杂的、基于 Spring Cloud 的微服务体系，完整地、云原生化地部署到了 Kubernetes 集群中，并为其配置了自动伸缩能力。

------



## **课程总结与展望**



恭喜你完成了 Kubernetes 的硬核之旅！现在，你已经：

- **完全掌握了 K8s 的核心概念和资源对象。**
- **具备了独立将任何容器化应用部署到 K8s 的能力。**
- **深刻理解了云原生时代的应用交付和运维模式。**

我们已经走完了从开发、治理到部署的完整流程。但一个真正的生产级系统，还需要最后两块拼图：

1. 如何将“代码提交”到“K8s 部署”这个过程自动化？—— **CI/CD**
2. 部署上去之后，如何全方位地监控系统的运行状态、快速排查问题？—— **可观测性**

这正是我们最后两门课程将要攻克的目标。准备好，向着全栈云原生专家的目标，发起最后的冲刺！

**感谢大家的学习，课程结束！**



好的，我们马上进入自动化领域的学习，这是连接开发与运维，实现高效软件交付的关键一环。

这是《第五门课：CI/CD与自动化运维：基于Jenkins/GitLab的微服务发布》的完整教学文档。本课程将打通从代码提交到生产部署的“最后一公里”，将我们之前的所有知识点串联成一条自动化的流水线。

------



# **第五门课：CI/CD与自动化运维：基于Jenkins/GitLab的微服务发布**





## **课程信息**



- **课程名称：** CI/CD与自动化运维：基于Jenkins/GitLab的微服务发布

  

## **课程概述 (Course Overview)**



欢迎来到云原生微服务系列课程的第五站！我们已经学会了如何开发、治理并手动部署一个完整的微服务系统到 Kubernetes。但是，在现代敏捷开发中，手动构建、测试、打包、上传镜像、更新部署…… 这一系列繁琐的流程是低效且极易出错的。如何将这个过程自动化，做到代码一次提交，即可自动触发后续所有发布流程？这就是本课程要解决的核心问题——CI/CD（持续集成/持续交付/持续部署）。

本课程将带您深入学习 CI/CD 的核心理念与实践，并以业界最流行的自动化服务器 Jenkins 为核心工具，从零开始搭建一套功能完备的自动化部署流水线（Pipeline）。您将学会如何使用 `Jenkinsfile` (Pipeline as Code) 来定义这条流水线，实现从拉取代码、执行单元测试、构建 Docker 镜像、推送到私有镜像仓库，再到自动更新 Kubernetes 中应用的完整流程。此外，我们还将介绍另一款优秀工具 GitLab CI/CD，作为 Jenkins 的对比和补充。学完本课程，您将掌握 DevOps 工程师的核心技能，具备构建企业级自动化发布体系的能力。



### **学习目标 (Learning Objectives)**



学完本课程后，您将能够：

1. **阐述** CI/CD 的核心概念、价值以及不同阶段的含义。
2. **独立部署和配置** Jenkins 服务器及相关构建工具。
3. **掌握** "Pipeline as Code" 的思想，并能熟练编写 `Jenkinsfile`。
4. **构建** 一条完整的自动化流水线，将微服务应用从代码仓库自动部署到 Kubernetes 集群。
5. **掌握** 流水线中凭证管理、参数化构建、消息通知等高级技巧。
6. **了解** GitLab CI/CD 的基本用法，并能实现类似的自动化流程。



### **目标学员 (Target Audience)**



- 已完成前四门课程，希望实现自动化部署的开发者和运维人员。
- 希望从传统软件发布流程转向现代化 DevOps 实践的工程师。
- 对自动化运维、敏捷交付感兴趣的技术人员。



### **前置要求 (Prerequisites)**



- **必须**：完成 **《第四门课：Kubernetes 实战》**，并拥有一个可用的 K8s 集群。
- **必须**：熟悉 Git 的基本操作（`clone`, `commit`, `push`等）。
- **必须**：拥有一个代码托管平台账号（GitHub, Gitee, or GitLab）。
- **必须**：拥有一个 Docker 镜像仓库（Docker Hub, Harbor, 阿里云ACR等）。



### **环境准备 (Environment Setup)**



1. **Kubernetes 集群**：本地 Docker Desktop K8s 或其他可用的 K8s 集群。
2. **Docker & kubectl**：确保本地已安装并可正常连接到 K8s 集群。
3. **代码仓库**：将我们之前的 `user-service`, `product-service` 等微服务项目上传到你的 Git 仓库。
4. **Jenkins Server**：我们将使用 Docker 来部署。
5. **Docker 镜像仓库**：推荐使用 **Harbor**（可以使用 Docker Compose 在本地快速部署），或者使用 Docker Hub。

------



## **第一章：CI/CD 核心理念与工具**





### **1.1 学习目标**



- 理解什么是持续集成 (CI)、持续交付 (CD)、持续部署 (CD)。
- 认识 CI/CD 对团队和业务的核心价值。
- 了解主流 CI/CD 工具的特点。
- 熟悉 Git Flow 等协作工作流。



### **1.2 理论讲解**



- **CI/CD 是什么？**
  - **持续集成 (Continuous Integration, CI)**：开发人员频繁地（每天多次）将代码合并到主干分支。每次合并都会自动触发**构建**和**单元测试**。
    - **核心目标**：尽早发现并解决集成错误。
  - **持续交付 (Continuous Delivery, CD)**：在 CI 的基础上，将通过所有测试的代码自动**部署到类生产环境**（如测试环境、预发布环境）。部署到**生产环境**的步骤需要**手动确认**。
    - **核心目标**：确保软件随时处于可发布状态。
  - **持续部署 (Continuous Deployment, CD)**：更进一步，将通过所有自动化测试的代码**自动部署到生产环境**。
    - **核心目标**：实现从代码提交到上线的全自动化。
- **CI/CD 的价值**
  - **加速交付**：自动化流程大大缩短了从开发到上线的时间。
  - **提升质量**：频繁的自动化测试能更早地发现 Bug。
  - **降低风险**：每次发布的变更范围小，发布过程自动化，减少了人为错误。
  - **增强开发者幸福感**：将开发者从重复、繁琐的发布工作中解放出来。
- **主流工具对比**
  - **Jenkins**: 开源、免费，插件生态极其丰富，社区强大，是老牌的王者，灵活性极高。
  - **GitLab CI/CD**: 与 GitLab 代码仓库深度集成，配置简单（一个 `.gitlab-ci.yml` 文件），开箱即用。
  - **GitHub Actions**: 与 GitHub 深度集成，近年来发展迅速，社区市场活跃，语法简洁。
- **Git 工作流 (Git Workflow)**
  - **Git Flow**: 一种功能强大但相对复杂的工作流，定义了 `master`, `develop`, `feature`, `release`, `hotfix` 等多种分支。适合大型、计划性强的项目。
  - **GitHub Flow**: 一种更轻量级的工作流。任何新功能或修复都在 `master` 分支拉出的 `feature` 分支上开发，完成后通过 Pull Request (PR) 合并回 `master`。CI/CD 通常在 PR 和 `master` 分支上触发。这是大多数项目推荐的模式。



### **1.3 本章小结**



我们理解了 CI/CD 是现代软件开发的“高速公路”，它通过自动化来提升软件交付的速度和质量。我们也对即将使用的工具有了初步的认识。

------



## **第二章：Jenkins 入门与核心配置**





### **2.1 学习目标**



- 使用 Docker 快速部署 Jenkins。
- 完成 Jenkins 的初始化配置。
- 安装必要的插件（如 Git, Maven, Docker）。
- 创建第一个自由风格（Freestyle）项目。



### **2.2 动手实战：搭建 Jenkins 服务器**



1. **使用 Docker 部署 Jenkins**

   - 创建一个 `docker-compose.yml` 文件来部署 Jenkins：

     YAML

     ```
     version: '3.8'
     services:
       jenkins:
         image: jenkins/jenkins:2.361.1-lts-jdk11 # 选择一个稳定的LTS版本
         container_name: jenkins
         ports:
           - "8080:8080"  # Web UI 端口
           - "50000:50000" # Agent 通信端口
         volumes:
           - jenkins_home:/var/jenkins_home # 数据持久化
           - /var/run/docker.sock:/var/run/docker.sock # 允许 Jenkins 调用宿主机的 Docker
           - /usr/bin/docker:/usr/bin/docker # 将宿主机的 docker 客户端映射进去
         user: root # 授权容器内的 jenkins 用户操作 docker
     
     volumes:
       jenkins_home:
     ```

   - 在该目录下执行 `docker-compose up -d`。

2. **初始化 Jenkins**

   - 访问 `http://localhost:8080`。
   - Jenkins 会要求输入初始管理员密码。根据提示，使用 `docker exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword` 查看密码并填入。
   - 选择“安装推荐的插件”。等待插件安装完成。
   - 创建第一个管理员用户。

3. **全局工具配置**

   - 进入 "Manage Jenkins" -> "Global Tool Configuration"。
   - **JDK**: 如果你使用的镜像没有自带 JDK，可以在这里配置。我们选择的镜像已包含 JDK11。
   - **Maven**: 点击 "Add Maven"，起一个名字（如 `Maven3.8`），选择“自动安装”。
   - **Git**: 通常无需配置，使用默认即可。

4. **创建第一个 Freestyle 项目**

   - 回到 Jenkins 首页，点击 "New Item"。
   - 输入项目名称（如 `freestyle-demo`），选择 "Freestyle project"，点击 "OK"。
   - **General**: 填写项目描述。
   - **Source Code Management**: 选择 "Git"，填入你的 Spring Boot 项目的仓库地址。
   - **Build Steps**: 点击 "Add build step"，选择 "Invoke top-level Maven targets"。
     - Maven Version: 选择我们刚才配置的 `Maven3.8`。
     - Goals: 输入 `clean package`。
   - 保存并点击 "Build Now"。
   - 在 "Build History" 中可以看到构建记录，点击进入可以查看 "Console Output"，验证项目是否打包成功。



### **2.3 本章小结**



我们成功搭建了 Jenkins 服务器，并完成了最基本的配置。通过 Freestyle 项目，我们体验了 Jenkins 从拉取代码到执行构建的自动化流程，为后续更复杂的 Pipeline 打下了基础。

------



## **第三章：Jenkins Pipeline as Code**





### **3.1 学习目标**



- 理解 Pipeline as Code 的优势。
- 掌握 Jenkinsfile 的声明式流水线（Declarative Pipeline）语法。
- 编写 Jenkinsfile 实现应用的自动化构建和 Docker 镜像打包。
- 将镜像推送到私有仓库，并管理凭证。



### **3.2 理论讲解**



- **为什么需要 Pipeline as Code？**

  - **版本控制**：流水线定义（`Jenkinsfile`）和项目代码一起存储在 Git 仓库中，可以追踪变更历史，进行 Code Review。
  - **可复用性**：可以创建模板化的流水线，供多个项目使用。
  - **可恢复性**：如果 Jenkins 服务器宕机，只需重新指向代码仓库，所有流水线任务都会恢复。
  - **团队协作**：团队成员都可以查看和修改流水线定义。

- **Jenkinsfile 声明式流水线基本结构**

  Groovy

  ```
  pipeline {
      agent any // 指定流水线在哪个执行器上运行，any 表示任意可用
  
      tools { // 定义需要的工具
          maven 'Maven3.8'
      }
  
      stages { // 流水线的所有阶段
          stage('Checkout') { // 第一个阶段：检出代码
              steps {
                  git 'your_repo_url'
              }
          }
          stage('Build') { // 第二个阶段：构建
              steps {
                  sh 'mvn clean package'
              }
          }
          // ...更多阶段
      }
  }
  ```



### **3.3 动手实战：构建 Docker 镜像流水线**



1. **在 Spring Boot 项目中创建 `Jenkinsfile`**

   - 在 `user-service` 项目的根目录下，创建一个名为 `Jenkinsfile` 的文件。

   - 输入以下内容：

     Groovy

     ```
     pipeline {
         agent any
     
         tools {
             maven 'Maven3.8'
         }
     
         environment {
             // 定义环境变量
             DOCKER_REGISTRY = 'your-harbor-address' // 你的Harbor仓库地址或Docker Hub用户名
             IMAGE_NAME = "library/${env.JOB_NAME}:${env.BUILD_NUMBER}" // 镜像名：library/user-service:1
         }
     
         stages {
             stage('Checkout') {
                 steps {
                     // Jenkins会自动从配置的仓库拉取代码
                     checkout scm
                 }
             }
     
             stage('Build') {
                 steps {
                     sh 'mvn clean package -DskipTests'
                 }
             }
     
             stage('Build Docker Image') {
                 steps {
                     sh "docker build -t ${DOCKER_REGISTRY}/${IMAGE_NAME} ."
                 }
             }
     
             stage('Push Docker Image') {
                 steps {
                     // 使用 withCredentials 来安全地使用凭证
                     withCredentials([usernamePassword(credentialsId: 'harbor-credentials', usernameVariable: 'USER', passwordVariable: 'PASS')]) {
                         sh "docker login -u ${USER} -p ${PASS} ${DOCKER_REGISTRY}"
                         sh "docker push ${DOCKER_REGISTRY}/${IMAGE_NAME}"
                         sh "docker logout ${DOCKER_REGISTRY}"
                     }
                 }
             }
         }
     }
     ```

2. **在 Jenkins 中配置凭证**

   - 进入 "Manage Jenkins" -> "Manage Credentials"。
   - 点击 "(global)" -> "Add Credentials"。
   - Kind: `Username with password`。
   - Scope: Global。
   - Username/Password: 输入你的 Docker 仓库的用户名和密码。
   - **ID**: `harbor-credentials` (必须与 `Jenkinsfile` 中的 `credentialsId` 一致)。

3. **创建 Pipeline 项目**

   - 回到 Jenkins 首页，点击 "New Item"。
   - 输入项目名称（如 `user-service-pipeline`），选择 "Pipeline"，点击 "OK"。
   - **Definition**: 选择 "Pipeline script from SCM"。
   - **SCM**: 选择 "Git"，填入你的 `user-service` 的仓库地址。
   - **Script Path**: 保持默认 `Jenkinsfile`。
   - 保存并点击 "Build Now"。

4. **观察流水线**

   - 你会看到 Jenkins 界面上出现了一个可视化的流水线，每个 `stage` 都会按顺序执行。你可以点击每个阶段查看其日志。
   - 执行成功后，去你的 Harbor 或 Docker Hub 仓库查看，新的镜像已经被成功推送上去了。



### **3.4 本章小结**



我们掌握了 Jenkins 最核心、最强大的功能——Pipeline as Code。通过编写 `Jenkinsfile`，我们以一种可控、可版本化的方式定义了从代码到镜像的自动化流程，为最终部署到 K8s 奠定了基础。

------



## **第四章：构建完整的微服务 CI/CD 流水线**





### **4.1 学习目标**



- 在 Jenkins Pipeline 中集成 `kubectl`。
- 编写部署脚本，实现应用的自动化部署和更新。
- 实现手动确认部署到生产环境的功能。



### **4.2 动手实战：自动部署到 K8s**



1. **准备 K8s 的 `kubeconfig` 凭证**

   - `kubectl` 需要 `~/.kube/config` 文件来连接 K8s 集群。我们需要将这个文件作为凭证存入 Jenkins。
   - 进入 "Manage Jenkins" -> "Manage Credentials" -> "Add Credentials"。
   - Kind: `Secret file`。
   - File: 上传你的 `config` 文件。
   - **ID**: `kubeconfig`。

2. **更新 `user-service` 的 K8s Deployment YAML**

   - 我们需要一个独立的 `user-service-deployment.yaml` 文件放在项目代码库中。

   - **关键修改**：镜像地址需要使用一个占位符，方便流水线替换。

     YAML

     ```
     ...
     spec:
       containers:
       - name: user-service
         image: __IMAGE_URL__ # 使用占位符
     ...
     ```

3. **更新 `Jenkinsfile`，增加部署阶段**

   Groovy

   ```
   // ... 前面的阶段不变 ...
   
   stage('Deploy to K8s') {
       // input 步骤会暂停流水线，等待用户手动确认
       input {
           message "Deploy to production?"
           ok "Yes, Deploy!"
       }
       steps {
           // 使用 kubeconfig 凭证
           withCredentials([file(credentialsId: 'kubeconfig', variable: 'KUBECONFIG_FILE')]) {
               script {
                   // 读取部署模板文件
                   def yamlContent = readFile 'user-service-deployment.yaml'
                   // 替换占位符为真实的镜像地址
                   def finalYaml = yamlContent.replace('__IMAGE_URL__', "${DOCKER_REGISTRY}/${IMAGE_NAME}")
   
                   // 将最终的 YAML 内容写入一个临时文件
                   writeFile file: 'final-deployment.yaml', text: finalYaml
   
                   // 执行 kubectl 命令
                   // 注意：需要确保 Jenkins 执行器能够访问 kubectl 命令
                   // 最好是创建一个包含 kubectl 的 Jenkins Agent 镜像
                   sh """
                   export KUBECONFIG=${KUBECONFIG_FILE}
                   kubectl apply -f final-deployment.yaml
                   kubectl rollout status deployment/user-service-deployment
                   """
               }
           }
       }
   }
   // ...
   ```

4. **运行并验证**

   - 提交 `Jenkinsfile` 和 `user-service-deployment.yaml` 的改动到 Git 仓库。
   - 触发 Jenkins 构建。
   - 流水线会在 "Deploy to K8s" 阶段暂停，你需要手动点击 "Yes, Deploy!"。
   - 部署成功后，使用 `kubectl get pods` 和 `kubectl describe deployment user-service-deployment` 来验证应用是否已经更新为最新的镜像版本。



### **4.3 本章小结**



我们成功打通了从代码提交到生产部署的全链路自动化！通过将 `kubectl` 集成到 Jenkins Pipeline 中，我们实现了真正的持续交付/部署，极大地提升了软件发布效率和可靠性。

------



## **第五章：GitLab CI/CD 实战 (简介)**





### **5.1 学习目标**



- 了解 GitLab CI/CD 的核心概念。
- 编写 `.gitlab-ci.yml` 文件实现自动化构建。



### **5.2 理论与实战**



- **核心概念**

  - **`.gitlab-ci.yml`**: 放在项目根目录的 YAML 文件，用于定义流水线。
  - **Runner**: 真正执行流水线任务的机器。可以是共享的，也可以是自己注册的专属 Runner。
  - **Stages**: 定义阶段，如 `build`, `test`, `deploy`。
  - **Jobs**: 在某个 `stage` 中执行的具体任务。

- **`.gitlab-ci.yml` 示例**

  YAML

  ```
  stages:
    - build
    - push
    - deploy
  
  build-job:
    stage: build
    script:
      - echo "Compiling the code..."
      - mvn clean package -DskipTests
    artifacts:
      paths:
        - target/*.jar # 将构建产物传递给下一阶段
  
  push-image-job:
    stage: push
    image: docker:20.10.16 # 使用 Docker 镜像来执行
    services:
      - docker:20.10.16-dind # 启动 Docker in Docker 服务
    script:
      - echo "Building & Pushing Docker image..."
      - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
      - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .
      - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  
  # deploy-job ... (类似)
  ```

  - GitLab CI/CD 的优势在于其内置的变量（如 `$CI_REGISTRY_IMAGE`）和与代码仓库的无缝集成。



### **5.3 本章小结**



我们快速了解了 GitLab CI/CD 这一强大的替代方案。对于使用 GitLab 作为代码仓库的团队，它提供了一种更简单、更集成的 CI/CD 体验。

------



## **课程总结与展望**



在本课程中，我们化身为 DevOps 工程师，构建了现代软件开发的“自动化引擎”：

- **掌握了 CI/CD 的核心思想。**
- **精通了使用 Jenkins Pipeline as Code 构建从代码到 K8s 的全自动化部署流水线。**
- **了解了 GitLab CI/CD 作为备选方案。**

现在，我们的系统已经可以自动化地开发、治理、部署了。但是，部署上线只是一个新的开始。系统在生产环境运行，它的健康状况如何？性能瓶颈在哪里？出现故障时如何快速定位？

这就是我们系列课程的最后一站—— **《第六门课：全方位可观测性 —— ELK 日志系统与 APM 链路追踪》** 将要解决的问题。我们将为系统装上“眼睛”和“耳朵”，进入云原生运维的最高境界。

**感谢大家的学习，课程结束！**



好的，我们迎来了这个系列课程的最后一站，也是从“能用”到“好用”，从“上线”到“高枕无忧”的终极蜕变。

这是《第六门课：全方位可观测性 —— ELK 日志系统与 APM 链路追踪》的完整教学文档。本课程将为我们精心构建的微服务体系装上“眼睛”、“耳朵”和“神经系统”，使其具备自我洞察的能力。

------



# **第六门课：全方位可观测性 —— ELK 日志系统与 APM 链路追踪**





## **课程信息**



- **课程名称：** 全方位可观测性 —— ELK 日志系统与 APM 链路追踪



## **课程概述 (Course Overview)**



恭喜您坚持到了最后一站！我们已经拥有了一套能够自动化开发、治理和部署的微服务系统。但是，当系统在生产环境的复杂网络中运行时，一个核心问题随之而来：系统内部正在发生什么？当用户报告“网站很慢”或“功能报错”时，我们如何快速定位问题根源？成百上千的服务实例产生的海量日志，又该如何有效管理和分析？

本课程将带您进入云原生运维的最高境界——**可观测性 (Observability)**。我们将学习可观测性的三大支柱：**日志 (Logging)**、**追踪 (Tracing)** 和 **指标 (Metrics)**。您将亲手使用业界最流行的开源工具栈，为我们的系统构建强大的“感知能力”：使用 **ELK/EFK 技术栈 (Elasticsearch, Logstash/Fluentd, Kibana)** 搭建集中式的日志平台，实现海量日志的统一采集、存储、搜索和可视化；使用 **SkyWalking** 作为应用性能监控（APM）和分布式链路追踪系统，以无侵入的方式洞察每一次跨服务的调用链，精准定位性能瓶颈和故障点。学完本课程，您将不再是“盲人摸象”式的运维，而是拥有了透视整个分布式系统内部运作的“X光”视野。



### **学习目标 (Learning Objectives)**



学完本课程后，您将能够：

1. **阐述** 可观测性的核心理念及其三大支柱。
2. **独立部署和使用 ELK Stack**，搭建企业级的集中式日志平台。
3. **掌握** 在 Kubernetes 环境下使用 Filebeat/Fluentd 自动采集容器日志的方案。
4. **熟练使用 Kibana** 进行日志的复杂查询、聚合分析和仪表盘制作。
5. **独立部署和使用 SkyWalking**，为微服务体系提供分布式链路追踪。
6. **具备** 结合链路追踪（TraceID）和集中式日志快速定位线上问题的综合排错能力。



### **目标学员 (Target Audience)**



- 已完成前五门课程，希望提升系统监控和运维能力的开发者与 DevOps 工程师。
- 希望构建强大的日志和监控系统，以保障生产环境稳定性的 SRE 工程师。
- 对分布式系统故障排查、性能优化感兴趣的技术人员。



### **前置要求 (Prerequisites)**



- **必须**：完成 **《第四门课：Kubernetes 实战》** 和 **《第五门课：CI/CD》**，拥有一个部署在 K8s 上的微服务系统。
- **必须**：熟悉 Docker 和 Docker Compose。
- **推荐**：对 Linux 系统和基本的 Shell 脚本有了解。



### **环境准备 (Environment Setup)**



1. **Kubernetes 集群**：继续使用之前的 K8s 集群。
2. **微服务项目**：继续使用 `user-service`, `product-service` 等项目。
3. **Docker & Docker Compose**：用于在本地快速部署 ELK 和 SkyWalking。
4. **充足的本地内存**：Elasticsearch 和 SkyWalking 是内存消耗大户，建议本地机器至少有 16GB 内存。

------



## **第一章：可观测性 (Observability) 导论**





### **1.1 学习目标**



- 区分传统监控 (Monitoring) 与现代可观测性 (Observability) 的差异。
- 理解可观测性三大支柱：日志、追踪、指标的定义和作用。
- 了解本课程将使用的核心技术栈。



### **1.2 理论讲解**



- **监控 vs 可观测性**
  - **监控 (Monitoring)**：**“我们知道该看什么”**。这是一种被动的、基于预设指标和阈值的系统观察方式。我们预先定义好要监控的指标（如 CPU 使用率、磁盘空间），当指标超过阈值时发出告警。它能回答**“已知”**的问题。
  - **可观测性 (Observability)**：**“我们能问任何想问的问题”**。这是一种主动的、探索式的系统洞察能力。我们通过收集足够丰富的数据（日志、追踪、指标），使得当系统出现**“未知”**的异常行为时，我们有能力通过分析这些数据来理解其内部状态并定位根源。
- **三大支柱 (The Three Pillars)**
  1. **日志 (Logging)**：记录了系统中发生的、离散的、带有时间戳的事件。日志提供了最详细、最具体的信息，是事后排错的**“底牌”**。
  2. **追踪 (Tracing)**：记录了一次请求在分布式系统中所经过的完整路径。它将跨越多个服务的调用串联起来，形成了**“上帝视角”**，是分析系统性能瓶颈、理解服务依赖关系的利器。
  3. **指标 (Metrics)**：可聚合的、数值型的数据，通常以时间序列的形式展现（如 QPS、请求延迟、CPU使用率）。指标是系统健康状况的**“仪表盘”**，适合用于告警和趋势分析。
- **三者关系**：它们相辅相成，从不同维度描绘了系统的状态。一个典型的排错流程可能是：`指标`发现异常（延迟升高） -> `追踪`定位到具体是哪个服务、哪个接口慢了 -> `日志`深入分析该接口在那个时间点的具体错误信息或上下文。



### **1.3 本章小结**



我们建立了对可观测性的正确认知，理解了它在复杂分布式系统中的重要性，并明确了三大支柱各自的角色和价值。

------



## **第二章：集中式日志平台 - ELK Stack**





### **2.1 学习目标**



- 了解 ELK 各组件的作用。
- 使用 Docker Compose 快速部署 ELK 环境。
- 改造 Spring Boot 应用，使其输出结构化的 JSON 日志。
- 使用 Kibana 进行日志查询和可视化。



### **2.2 理论讲解**



- **ELK Stack 架构**
  - **E - Elasticsearch**: 一个基于 Lucene 的分布式搜索和分析引擎。负责**存储**和**索引**海量日志数据，并提供快速的全文检索能力。
  - **L - Logstash**: 一个强大的数据处理管道。负责**采集**、**过滤**、**转换**各种来源的日志数据，然后将其发送到 Elasticsearch。
  - **K - Kibana**: 一个数据可视化平台。负责提供一个 Web UI，让用户可以方便地**搜索**、**分析**和**可视化**存储在 Elasticsearch 中的数据。
  - **Beats**: 轻量级的数据采集器家族，通常用于替代 Logstash 的采集功能。其中 **Filebeat** 最为常用，专门用于采集日志文件。现代架构通常是 `Beats -> Logstash -> Elasticsearch -> Kibana` 或 `Beats -> Elasticsearch -> Kibana`。



### **2.3 动手实战：搭建 ELK 并采集应用日志**



1. **使用 Docker Compose 部署 ELK**

   - 创建一个 docker-compose-elk.yml 文件：

     (此处提供一个包含 Elasticsearch, Logstash, Kibana 的完整 Compose 文件，并配置好它们之间的网络和依赖关系)

   - 执行 `docker-compose -f docker-compose-elk.yml up -d`。

2. **改造 Spring Boot 日志输出**

   - **目标**：让日志输出为 JSON 格式，方便 Elasticsearch 解析。

   - **第一步：添加依赖** `logstash-logback-encoder`。

   - **第二步：创建 `logback-spring.xml`**。在 `src/main/resources` 下配置 Logback，使用 `LogstashTcpSocketAppender` 将 JSON 格式的日志直接发送到 Logstash。

     XML

     ```
     <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
         <destination>localhost:5044</destination> <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
     </appender>
     
     <root level="INFO">
         <appender-ref ref="LOGSTASH" />
         <appender-ref ref="CONSOLE" />
     </root>
     ```

3. **配置 Logstash**

   - 在 Logstash 的配置文件 (`logstash.conf`) 中，设置 input 和 output：

     Code snippet

     ```
     input {
       tcp {
         port => 5044
         codec => json_lines
       }
     }
     output {
       elasticsearch {
         hosts => ["http://elasticsearch:9200"]
         index => "springboot-logs-%{+YYYY.MM.dd}"
       }
     }
     ```

4. **Kibana 实战**

   - 访问 Kibana (`http://localhost:5601`)。
   - 进入 "Stack Management" -> "Index Patterns"，创建一个索引模式，如 `springboot-logs-*`，以匹配 Logstash 创建的索引。
   - 进入 "Discover" 模块，你现在就可以看到从 Spring Boot 应用发送过来的日志了！
   - **尝试查询**：
     - `level: ERROR`：只看错误日志。
     - `message: "user not found"`：全文搜索。
     - `trace.trace_id: "xxx"`：(预告) 根据 TraceID 查询特定请求的所有日志。



### **2.4 本章小结**



我们成功搭建了 ELK 集中式日志平台，并打通了从应用产生日志到 Kibana 可视化展现的全链路，告别了 `ssh` 到服务器上 `grep` 日志的原始时代。

------



## **第三章：Kubernetes 环境下的日志采集 - EFK**





### **3.1 学习目标**



- 理解在 K8s 中采集日志的挑战。
- 使用 Filebeat (DaemonSet) 模式自动发现并采集所有 Pod 的日志。



### **3.2 理论讲解**



- **K8s 日志采集的挑战**：Pod 是动态创建和销毁的，IP 地址不固定。我们不可能为每个 Pod 手动配置日志采集。
- **标准解决方案**：在**每个 Node** 上都运行一个日志采集代理（如 Filebeat 或 Fluentd），该代理负责收集本节点上**所有**容器的标准输出（stdout）日志。这种部署模式在 K8s 中被称为 **DaemonSet**。
- **EFK 架构**：即 `Elasticsearch` + `Fluentd` + `Kibana`。Fluentd 是另一个流行的日志采集工具，与 Filebeat 功能类似，在 K8s 社区中同样非常流行。本课程我们以 `Filebeat` 为例，因为它与 ELK 的集成更为原生。



### **3.3 动手实战：部署 Filebeat DaemonSet**



1. **准备 Filebeat 的 K8s 配置文件**
   - (此处提供一个完整的 Filebeat DaemonSet YAML 文件)
   - **核心配置点**：
     - **Kind**: `DaemonSet`，确保每个 Node 有一个 Filebeat Pod。
     - **VolumeMounts**: 将宿主机的 Docker 日志目录 (如 `/var/lib/docker/containers`) 挂载到 Filebeat Pod 内部。
     - **Filebeat ConfigMap**: 配置 Filebeat 如何发现、解析容器日志，并将其发送到我们之前搭建的 Elasticsearch 或 Logstash。
     - **RBAC**: 配置必要的权限，允许 Filebeat Pod 访问 K8s API 来获取 Pod 的元数据（如 Pod 名称、标签等），并将这些元数据附加到日志中，方便筛选。
2. **部署到 K8s**
   - `kubectl apply -f filebeat-k8s-daemonset.yaml`
3. **验证**
   - 在 Kibana 中，你会看到来自 K8s 集群中所有 Pod（包括 `user-service`, `product-service` 等）的日志源源不断地汇入。
   - 日志中会包含 `kubernetes.pod.name`, `kubernetes.namespace` 等丰富的元数据，你可以非常方便地筛选特定应用的日志。



### **3.4 本章小结**



我们解决了在动态、分布式的 K8s 环境中进行日志采集的难题。通过 DaemonSet 模式，我们实现了一套“一劳永逸”的自动化日志采集方案。

------



## **第四章：分布式链路追踪 - SkyWalking**





### **4.1 学习目标**



- 理解分布式链路追踪的核心概念 (Trace, Span)。
- 使用 Docker 部署 SkyWalking。
- 以无侵入的方式为微服务集成 SkyWalking Agent。
- 使用 SkyWalking UI 分析服务拓扑和请求链路。



### **4.2 理论讲解**



- **为什么需要链路追踪？**
  - 在微服务架构中，一个用户请求可能会经过网关、订单服务、用户服务、库存服务等多个环节。如果请求变慢或出错，我们需要一种方法来追踪它走过的完整路径，从而快速定位是哪个环节出了问题。
- **核心概念**
  - **Trace**: 代表一个完整的请求链路，由多个 Span 组成，拥有一个全局唯一的 `TraceID`。
  - **Span**: 代表链路中的一个工作单元或操作，如一次 HTTP 调用、一次数据库查询。每个 Span 有自己的 `SpanID`，并记录了操作的起止时间。Span 之间可以有父子关系，构成一棵树状的调用链。
- **SkyWalking 是如何工作的？**
  - 它采用 **Java Agent** 技术，在应用启动时，通过 JVM 参数将其“挂载”到我们的 Java 进程上。
  - Agent 会**自动**拦截所有主流框架（Spring MVC, Feign, JDBC, Redis客户端等）的调用，生成 Span 数据，并将它们上报给 SkyWalking 的 OAP (Observability Analysis Platform) 服务器进行分析和存储。
  - 整个过程对我们的**业务代码完全透明，无需修改一行代码**。



### **4.3 动手实战：集成 SkyWalking**



1. **使用 Docker Compose 部署 SkyWalking**

   - (此处提供一个包含 skywalking-oap, skywalking-ui, elasticsearch 的 Compose 文件)
   - `docker-compose -f docker-compose-skywalking.yml up -d`
   - 访问 SkyWalking UI: `http://localhost:8080`

2. **为微服务集成 Agent**

   - **第一步：下载 SkyWalking Agent**。从 SkyWalking 官网下载与你服务端版本匹配的 Agent 发行版并解压。

   - **第二步：修改 `Dockerfile`**。将 Agent 添加到镜像中。

     Dockerfile

     ```
     # ... (之前的构建阶段)
     
     FROM openjdk:8-jre-slim
     
     # 将 Agent 复制到镜像中
     COPY --from=builder /path/to/skywalking-agent /skywalking/agent
     
     # ... (复制 jar 包)
     
     # 修改启动命令，通过 -javaagent 参数挂载 Agent
     ENTRYPOINT ["java", "-javaagent:/skywalking/agent/skywalking-agent.jar", "-Dskywalking.agent.service_name=user-service", "-Dskywalking.collector.backend_service=skywalking-oap:11800", "-jar", "app.jar"]
     ```

     - `-Dskywalking.agent.service_name`: 指定服务名。
     - `-Dskywalking.collector.backend_service`: 指定 OAP 服务器地址。

   - **第三步：重新构建并部署所有微服务镜像。**

3. **分析与探索**

   - 重新部署后，用 Postman 调用几次经过网关的 API。
   - 回到 SkyWalking UI：
     - **拓扑图 (Topology)**：你会看到一张自动生成的、酷炫的服务依赖关系图。
     - **追踪 (Trace)**：这里列出了所有的请求 Trace。点击任意一个 TraceID，你可以看到一个瀑布流图，清晰地展示了请求从 Gateway 到 Product-Service 再到 User-Service 的完整调用链，以及每个环节的耗时。
     - **端点 (Endpoint)**：分析每个接口（端点）的平均耗时、QPS、慢请求等。



### **4.4 本章小结**



我们为系统装上了强大的“雷达”，通过 SkyWalking 实现了对分布式调用链的无侵入式监控。现在，任何性能瓶颈和调用异常都将在我们面前无所遁形。

------



## **第五章：综合实战：从告警到根源**





### **5.1 学习目标**



- 建立一套结合三大支柱的、高效的线上问题排查流程。



### **5.2 实战演练**



1. **模拟场景**
   - 运维团队通过 Prometheus (指标监控系统) 发现 `/product-api/products/{id}/with-user` 接口的 P99 延迟突然飙升，触发了告警。
2. **第一步：使用 SkyWalking 定位问题域**
   - 打开 SkyWalking UI，找到该端点，查看其慢请求的追踪。
   - 在 Trace 的瀑布流中，发现 `Product-Service` 调用 `User-Service` 的 `findById` 这个 Feign 客户端 Span 耗时非常长。问题初步定位在 `User-Service`。
   - 复制这个 Trace 的 `TraceID`。
3. **第二步：使用 Kibana 深入根源**
   - 打开 Kibana。
   - 在查询框中输入 `trace.id: "刚才复制的TraceID"`。
   - 瞬间，Kibana 过滤出了这次慢请求在 `Gateway`, `Product-Service`, `User-Service` 中产生的所有相关日志！
   - 逐一排查日志，发现在 `User-Service` 的日志中有一条慢 SQL 查询记录，耗时占了整个请求的 90%。
4. **第三步：解决问题**
   - 将慢 SQL 交给 DBA 或开发人员进行分析和优化（例如，添加索引）。



### **5.3 本章小结**



我们演练了一套真实、高效的线上问题排查流程，深刻体会了将日志、追踪、指标结合起来的威力。这标志着我们已经具备了保障复杂分布式系统稳定运行的核心运维能力。

------



# **第七门课：生态整合与实践 —— 基于华为云 CSE 的微服务改造**



## **课程信息**



- **课程名称：** 生态整合与实践 —— 基于华为云 CSE 的微服务改造



## **课程概述 (Course Overview)**



在前序课程中，我们已经掌握了如何将单体应用拆分为微服务，并学习了使用 Spring Cloud Alibaba 这一开源组合拳来治理我们的服务。然而，在企业实践中，我们常常会面临另一种选择：直接采用云厂商提供的一站式、高集成度的微服务解决方案。

本课程将聚焦于华为云的核心中间件服务 —— **云服务引擎 (Cloud Service Engine, CSE)**。CSE 基于业界领先的开源项目 Apache ServiceComb 构建，并与华为云生态深度融合，提供了开箱即用的服务注册发现、配置管理、微服务网关和全方位监控能力。我们将以第二门课拆分出的微服务为基础，学习如何将其无缝对接到 CSE 平台，体验与公有云服务深度集成所带来的开发与运维便利性。通过本课程，您将能够跳出单一的技术栈，站在更高的维度去比较和选择最适合您业务场景的微服务解决方案。



### **学习目标 (Learning Objectives)**



学完本课程后，您将能够：

1. **理解** 华为云 CSE 的核心架构和产品价值。
2. **掌握** 如何将现有的 Spring Boot 微服务项目接入 CSE 的服务中心，实现服务的注册与发现。
3. **使用** CSE 的配置中心（Kie）实现应用配置的云端托管和动态管理。
4. **配置和使用** CSE 微服务网关，为服务提供统一的流量入口和精细化的 API 策略。
5. **体验** CSE 与华为云 APM、LTS 等其他云服务的无缝集成，实现“零配置”的可观测性。
6. **能够** 对比分析开源微服务框架与云厂商托管服务的优劣势。



### **目标学员 (Target Audience)**



- 已完成前两门课程，希望拓宽技术视野的开发者。
- 正在使用或计划采用华为云技术栈的企业和团队。
- 希望了解云原生时代下，云厂商如何提供微服务解决方案的架构师和技术决策者。



### **前置要求 (Prerequisites)**



- **必须**：完成 **《第二门课：从单体到微服务》**，并拥有拆分后的 `user-service` 和 `product-service` 项目代码。
- **必须**：拥有一个可用的**华为云账号**，并完成实名认证。
- **必须**：熟悉 Spring Boot 应用的基本开发和配置。
- **推荐**：对微服务治理的基本概念（注册中心、配置中心、网关）有所了解。



### **环境准备 (Environment Setup)**



1. **IDE, JDK, Maven**：与之前课程保持一致。
2. **华为云账号**：确保可以登录华为云控制台。
3. **Access Key & Secret Key (AK/SK)**：在华为云“我的凭证” -> “访问密钥”中创建，用于程序化访问云服务。
4. **微服务项目**：准备好 `user-service` 和 `product-service` 的代码。

------



## **第一章：初识华为云 CSE 与 ServiceComb**





### **1.1 学习目标**



- 了解华为云微服务解决方案的整体布局。
- 理解 CSE 的核心组件和其开源基础 Apache ServiceComb。
- 在华为云控制台成功创建一个 CSE 引擎实例。



### **1.2 理论讲解**



- **华为云上的微服务生态**
  - **CSE (Cloud Service Engine)**: 微服务治理的核心，提供注册/配置中心、微服务网关。
  - **CCE (Cloud Container Engine)**: 容器运行平台，即华为云的 Kubernetes 服务。
  - **APM (Application Performance Management)**: 应用性能管理，提供链路追踪、性能分析。
  - **LTS (Log Tank Service)**: 日志服务，用于日志的集中采集与分析。
  - 它们共同构成了一个完整的开发、部署、运维闭环。
- **CSE 与 Apache ServiceComb**
  - **Apache ServiceComb**: 一套开源的微服务解决方案，包含了服务契约、编程模型、运行框架等。
  - **CSE**: 是 ServiceComb 的商业化、云上托管版本，免去了用户自行搭建和维护的复杂性，并与华为云其他服务深度集成。
- **CSE 引擎类型**
  - CSE 支持多种类型的引擎作为其“内核”，如 `Nacos`、`Service-Center` (ServiceComb 原生注册中心)等，提供了灵活的选择。本课程我们将以 Nacos 引擎为例，方便与第三门课进行对比。



### **1.3 动手实战：创建 CSE 实例**



1. **登录华为云控制台**。
2. 在顶部搜索栏搜索“云服务引擎 CSE”，进入服务页面。
3. 点击“购买微服务引擎”，进入创建页面。
4. **关键配置**：
   - **引擎类型**: 选择 `Nacos`。
   - **版本**: 选择一个主流稳定版。
   - **规格**: 选择最低规格的开发测试版即可。
   - **网络**: 为了方便本地开发机连接，可以暂时绑定一个“弹性公网IP”。
   - **认证信息**: 设置 Nacos 控制台的登录密码。
5. 确认配置并完成创建。等待几分钟，直到引擎实例状态变为“正常”。
6. 进入实例详情页，记录下 **Nacos 控制台的公网访问地址** 和 **服务接入点地址 (Endpoint)**。
7. 尝试使用公网地址和刚才设置的密码登录 Nacos 控制台，验证实例是否正常工作。



### **1.4 本章小结**



我们了解了 CSE 在华为云生态中的定位，并通过控制台成功创建了后续实验所需的基础设施——一个云上托管的 Nacos 引擎。

------



## **第二章：服务注册与发现 with CSE**





### **2.1 学习目标**



- 学习如何通过华为云 SDK (huaweicloud-sdk-java-cse) 将 Spring Boot 应用接入 CSE。
- 实现服务的自动注册与发现。
- 改造 OpenFeign，使其通过 CSE 发现和调用服务。



### **2.2 动手实战：接入 CSE 服务中心**



1. **添加依赖**

   - 在 `user-service` 和 `product-service` 的 `pom.xml` 中，添加华为云 CSE 的 Spring Cloud starter。

     XML

     ```
     <dependencyManagement>
         <dependencies>
             <dependency>
                 <groupId>com.huaweicloud</groupId>
                 <artifactId>huaweicloud-solutions-bom</artifactId>
                 <version>1.2.1</version> <type>pom</type>
                 <scope>import</scope>
             </dependency>
         </dependencies>
     </dependencyManagement>
     
     <dependency>
         <groupId>com.huaweicloud</groupId>
         <artifactId>spring-cloud-starter-huaweicloud-cse</artifactId>
     </dependency>
     ```

2. **修改配置 `application.yml`**

   - 这是与开源 Nacos 最大的不同之处，CSE 的接入需要配置云服务的认证信息和接入点。

     YAML

     ```
     spring:
       application:
         name: user-service # 服务名
       cloud:
         huaweicloud:
           cse:
             service:
               registry:
                 address: https://cse.ap-southeast-1.myhuaweicloud.com # 替换为你的CSE接入点地址
           aksk:
             # 推荐使用环境变量或外部配置文件，此处为演示方便
             enabled: true
             accessKey: your_ak # 替换为你的 Access Key
             secretKey: your_sk # 替换为你的 Secret Key
             project: cn-north-4 # 替换为你的项目所在区域
     ```

   - 对 `product-service` 做同样的修改。

3. **验证服务注册**

   - **依次启动 `user-service` 和 `product-service`。**
   - 观察应用的启动日志，你会看到一系列与华为云 CSE 交互、鉴权和注册的日志。
   - 登录到我们创建的 CSE Nacos 控制台，在服务列表中，可以看到 `user-service` 和 `product-service` 已经成功注册。

4. **改造 OpenFeign**

   - 华为云的 Starter 已经很好地集成了 Spring Cloud 原生组件。理论上，我们在第三门课中为 Nacos 修改的 OpenFeign 客户端**无需任何改动**！

     Java

     ```
     // product-service 中的 UserClient.java 应该保持原样
     @FeignClient("user-service")
     public interface UserClient {
         // ...
     }
     ```

   - 启动 `product-service`，并用 Postman 调用需要访问用户服务的接口。

   - **结果**：调用成功！这证明了 `product-service` 通过华为云 CSE 发现了 `user-service` 的实例地址，并完成了调用。



### **2.3 本章小结**



我们成功地将本地微服务注册到了云端的 CSE 引擎，体验了云厂商解决方案带来的接入便利性。整个过程除了配置文件的差异，对业务代码几乎没有侵入。

------



## **第三章：集中配置管理 with CSE**





### **3.1 学习目标**



- 使用 CSE 的配置中心（Kie）来管理微服务配置。
- 实现配置的动态刷新。



### **3.2 动手实战：接入 CSE 配置中心**



1. **在 CSE 控制台创建配置**

   - 进入华为云 CSE 控制台，在左侧导航栏找到“配置中心 (Kie)”。

   - 点击“创建配置项”。

   - **键 (Key)**：例如 `user-service`。

   - **标签 (Labels)**：可以用来区分环境，如 `app: user-service`, `environment: development`。

   - **值 (Value)**：以 `key: value` 的形式写入应用的配置，例如：

     YAML

     ```
     # 这是配置项 user-service 的“值”
     db:
       url: jdbc:mysql://...
       username: root
     
     custom:
       greeting: "Hello from CSE Kie!"
     ```

2. **微服务接入配置中心**

   - 同样，`spring-cloud-starter-huaweicloud-cse` 已经包含了配置中心的功能。我们需要在 `bootstrap.yml` 中启用它。

   - 在 `user-service` 的 `src/main/resources` 下创建 `bootstrap.yml`：

     YAML

     ```
     spring:
       cloud:
         huaweicloud:
           cse:
             config:
               enabled: true # 启用配置中心
               server: https://cse.ap-southeast-1.myhuaweicloud.com # 替换为你的CSE接入点
     ```

3. **验证配置加载与动态刷新**

   - 参照第三门课的实战，在 `user-service` 中创建一个 Controller 来读取 `custom.greeting` 配置。
   - **不要忘记**在 Controller 类上添加 `@RefreshScope` 注解。
   - 启动 `user-service`，访问该接口，应该能看到 "Hello from CSE Kie!"。
   - 回到 CSE Kie 控制台，修改 `custom.greeting` 的值并保存。
   - 再次访问接口，**无需重启**，返回内容已经更新。



### **3.3 本章小结**



我们体验了 CSE 配置中心的云端管理能力。将配置托管到云上，不仅实现了集中管理，还天然具备了版本控制、权限管理等企业级特性。

------



## **第四章：统一访问入口 - CSE 微服务网关**





### **4.1 学习目标**



- 了解 CSE 微服务网关与 Spring Cloud Gateway 的区别。
- 在 CSE 控制台配置 API 路由规则。
- 体验网关自带的限流、认证等策略。



### **4.2 理论与实战**



- **CSE 微服务网关**
  - 它是一个**托管式**、**独立**的网关产品，你**不需要自己编写和部署一个网关应用**。
  - 所有的 API 路由、安全策略、流量控制等，都在**华为云控制台的 UI 界面上**进行配置，即刻生效。
- **动手实战：配置 API 路由**
  1. 进入华为云 CSE 控制台，左侧导航栏找到“微服务网关”。
  2. 点击“创建微服务网关”。选择一个基础的规格，并绑定一个公网 IP。
  3. 网关创建成功后，进入管理页面，选择“API管理” -> “新建API”。
  4. **配置后端为 `user-service` 的 API**：
     - **请求协议/路径**: `HTTP`, `/cloud/users/{id}`
     - **后端类型**: `微服务`
     - **微服务**: 在下拉框中选择我们注册的 `user-service`
     - **后端路径**: `/users/{id}`
     - 点击完成。
  5. 用同样的方式，为 `product-service` 也创建一个 API。
  6. 发布 API 到“生产”环境。
  7. **测试**：使用 Postman，通过**微服务网关的公网 IP**，访问 `http://[网关IP]/cloud/users/1`。请求应该能被成功路由到后端的 `user-service`。
- **体验高级功能**
  - 在 API 管理页面，找到刚才创建的 API，可以为它配置各种策略。
  - **流量控制**：设置 QPS 限制为 10。
  - **安全认证**：配置“应用认证(AppCode)”，生成一个 AppCode，要求客户端请求时必须在 Header 中携带正确的 AppCode。



### **4.3 本章小结**



我们体验了托管式微服务网关的巨大便利性。通过简单的 UI 操作，就完成了复杂的 API 路由和安全策略配置，大大降低了网关的维护成本。

------



## **第五章：生态整合与“零配置”可观测性**





### **5.1 学习目标**



- 体验 CSE 与华为云 APM、LTS 的无缝集成。



### **5.2 演示与探索**



- **分布式链路追踪 (APM)**
  - 因为我们使用了华为云的 CSE Starter，它内部已经集成了 APM 的探针逻辑。
  - 进入华为云控制台 -> **应用性能管理 (APM)**。
  - 在应用列表中，你会惊喜地发现，我们的 `user-service` 和 `product-service` **已经自动出现在这里了**！
  - 不需要像开源方案那样手动部署 SkyWalking、手动集成 Agent。
  - 点击应用，你可以看到熟悉的**拓扑图**、**调用链追踪**、**慢接口分析**等，所有功能一应俱全。
- **集中式日志 (LTS)**
  - 如果我们的微服务是部署在华为云的容器服务 CCE 或虚拟机 ECS 上的。
  - 我们只需要为 CCE/ECS 安装一个 LTS 的采集插件 (Agent)。
  - 之后，所有容器或虚拟机的日志就会**自动被采集**到 **日志坦克服务 (LTS)** 中。
  - 在 LTS 控制台，我们可以像使用 Kibana 一样，对所有日志进行集中的搜索、分析和告警。



### **5.3 本章小结**



本章完美地展示了使用云厂商一体化解决方案的核心优势——**生态整合**。通过简单的接入，我们就免费获得了原本需要复杂搭建和维护的“可观测性”能力，这极大地降低了中小企业的技术门槛和运维成本。

------



## **课程总结与展望**



在本课程中，我们踏上了一条与开源社区不同的微服务实现路径：

- **我们学会了如何将应用与华为云 CSE 平台进行深度整合。**
- **我们体验了通过云控制台“点一点”就完成服务治理的便捷。**
- **我们深刻感受到了云生态整合所带来的“开箱即用”的强大能力。**

现在，你的技术武器库中，已经有了两套强大的微服务解决方案：

1. **以 Spring Cloud Alibaba 为核心的开源技术栈**：灵活、自主可控、无厂商锁定，但需要一定的技术投入来搭建和维护。
2. **以华为云 CSE 为核心的云原生托管方案**：开箱即用、与云生态深度融合、运维成本低，但与云厂商有一定程度的绑定。

**没有最好的技术，只有最适合场景的技术。** 掌握了这两种模式，你将能够根据团队的技术实力、业务的发展阶段和成本考量，做出最明智、最专业的架构选型。

**祝贺你，完成了本次对云厂商生态的探索之旅！**

**全系列课程结束！**
